{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2\n",
    "* CSCI-5930 ML Fall 2021  (Be sure to discard which section you are not enrolled)\n",
    "* Author: Kerry Gip (Replace my name with yours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from time import *\n",
    "# First load the dataset into pandas dataframe\n",
    "full_dataset = pd.read_csv('dataset/baby-weights-dataset.csv',delimiter=',')\n",
    "judge_dataset = pd.read_csv('dataset/judge-without-labels.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks for everyone (Tasks 1-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: \n",
    "Separate the full_dataset into two parts: X and y, where X denotes the input matrix containing only the input (i.e., independent explanatory) variables, and y denotes the target variable containing only the target values for exactly the same number of samples in the given full_dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#input matrix - all but last column\n",
    "X = full_dataset.iloc[:, full_dataset.columns != 'BWEIGHT']\n",
    "\n",
    "#target variables - just the last column \n",
    "#Very last column is \"BWEIGHT\", that tells the true weight of the new-born (in lbs unit).\n",
    "#Actually, this needs to be considered as the target variable here.\n",
    "#y = full_dataset.iloc[: , -1:]\n",
    "#df[df.columns[-1]]\n",
    "y = full_dataset.iloc[:, full_dataset.columns == 'BWEIGHT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  ...  \\\n",
       "0  2001    2        1    33    26.0      10    34   12.0      4       2  ...   \n",
       "1  2002    2        2    19    40.0      10    18   11.0     12       1  ...   \n",
       "2  2003    2        1    33    16.0      14    31   16.0     16       2  ...   \n",
       "3  2004    1        1    25    40.0      15    28   12.0     12       3  ...   \n",
       "4  2005    1        2    21    60.0      13    20   12.0     14       2  ...   \n",
       "\n",
       "   HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT PRETERM RENAL  RHSEN  \\\n",
       "0         0        0        0       0       0        0       0     0      0   \n",
       "1         0        0        0       0       0        0       0     0      0   \n",
       "2         0        0        0       0       0        0       0     0      0   \n",
       "3         0        0        0       0       0        0       0     0      0   \n",
       "4         0        0        1       0       0        0       0     0      0   \n",
       "\n",
       "   UTERINE  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BWEIGHT\n",
       "0   4.3750\n",
       "1   6.9375\n",
       "2   8.5000\n",
       "3   8.5000\n",
       "4   9.0000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2:\n",
    "* Given X representing the input matrix from the full_dataset, y being the target vector (the rightmost column of the full_dataset), obtained from Task 1: \n",
    "* randomly split the (X,y) dataset into 75% for training and 25% for testing using the library function from the library [sklearn.model_selection](https://urldefense.com/v3/__https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html__;!!CXsS5Xclluo!34J7Vol-cvnN-I7o-iHw5CdltH-laBqpLbJDISG_-4diCU0yfgjcAxgAOZha7dg7nAI$ ) . Please pass to the train_test_split function an additional argument random_state=45931.\n",
    "* Store the 4 splits as X_train, X_test, y_train, y_test respectively.\n",
    "* Save the ID column for X_train and X_test into ID_train and ID_test as list variable.\n",
    "* Now, drop the ID columns from both X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,  random_state=45931)\n",
    "\n",
    "#saving ID columns\n",
    "ID_train = X_train[\"ID\"]\n",
    "ID_test = X_test[\"ID\"] \n",
    "\n",
    "\n",
    "#removing ID columns\n",
    "X_train =X_train.iloc[:, X_train.columns != 'ID'] \n",
    "X_test = X_test.iloc[:, X_test.columns != 'ID']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16961    18962\n",
       "28131    30132\n",
       "35114    37115\n",
       "85941    87942\n",
       "26819    28820\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16961</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28131</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35114</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85941</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62226</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>51.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87904</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32338</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27127</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28789</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  \\\n",
       "16961    1        1    36    50.0      16    32   12.0     13       3      0   \n",
       "28131    2        2    23    50.0      13    20   12.0     15       2      0   \n",
       "35114    1        1    26    38.0      11    21   12.0     13       1      0   \n",
       "85941    1        2    22    20.0      10    19   12.0     12       1      0   \n",
       "26819    2        1    35    30.0      13    30   16.0     17       3      0   \n",
       "...    ...      ...   ...     ...     ...   ...    ...    ...     ...    ...   \n",
       "62226    1        2    19    51.0      18    18   12.0     12       1      0   \n",
       "87904    2        2    42    38.0       4    27    9.0     11       5      0   \n",
       "32338    1        1    37    30.0      10    31   14.0     14       2      0   \n",
       "27127    1        1    23    23.0      13    37   12.0     14       2      0   \n",
       "28789    2        1    31    24.0      10    31   17.0     16       2      0   \n",
       "\n",
       "       ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX PINFANT PRETERM  RENAL  \\\n",
       "16961  ...         0        0        0       0       0       1       0      0   \n",
       "28131  ...         0        0        0       0       0       0       0      0   \n",
       "35114  ...         0        0        1       0       0       0       0      0   \n",
       "85941  ...         0        0        0       0       0       0       0      0   \n",
       "26819  ...         0        0        0       0       0       0       0      0   \n",
       "...    ...       ...      ...      ...     ...     ...     ...     ...    ...   \n",
       "62226  ...         0        0        0       0       0       0       0      0   \n",
       "87904  ...         0        0        0       0       0       0       0      0   \n",
       "32338  ...         0        0        0       0       0       0       0      0   \n",
       "27127  ...         0        0        0       0       0       0       0      0   \n",
       "28789  ...         0        0        0       0       0       0       0      0   \n",
       "\n",
       "       RHSEN  UTERINE  \n",
       "16961      0        0  \n",
       "28131      0        0  \n",
       "35114      0        0  \n",
       "85941      0        0  \n",
       "26819      0        0  \n",
       "...      ...      ...  \n",
       "62226      0        0  \n",
       "87904      0        0  \n",
       "32338      0        0  \n",
       "27127      0        0  \n",
       "28789      0        0  \n",
       "\n",
       "[76050 rows x 35 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40925      42926\n",
       "46370      48371\n",
       "78590      80591\n",
       "101381    103382\n",
       "43749      45750\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40925</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46370</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78590</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101381</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43749</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  \\\n",
       "40925     2        1    30    33.0      16    29   16.0     17       1      0   \n",
       "46370     2        1    23    20.0      10    22   12.0     15       2      0   \n",
       "78590     1        2    24    34.0      12    21   10.0     14       2      0   \n",
       "101381    2        1    32    16.0      15    28   12.0     13       2      0   \n",
       "43749     2        1    26    30.0       7    30   16.0     16       4      0   \n",
       "\n",
       "        ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX PINFANT PRETERM  \\\n",
       "40925   ...         0        0        0       0       0       0       0   \n",
       "46370   ...         0        1        0       0       0       0       0   \n",
       "78590   ...         0        0        0       0       0       0       0   \n",
       "101381  ...         0        0        0       0       0       0       0   \n",
       "43749   ...         0        0        0       0       0       0       0   \n",
       "\n",
       "        RENAL  RHSEN  UTERINE  \n",
       "40925       0      0        0  \n",
       "46370       0      0        0  \n",
       "78590       0      0        0  \n",
       "101381      0      0        0  \n",
       "43749       0      0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16961</th>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28131</th>\n",
       "      <td>9.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35114</th>\n",
       "      <td>7.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85941</th>\n",
       "      <td>6.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>7.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62226</th>\n",
       "      <td>8.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87904</th>\n",
       "      <td>8.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32338</th>\n",
       "      <td>8.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27127</th>\n",
       "      <td>8.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28789</th>\n",
       "      <td>8.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BWEIGHT\n",
       "16961   9.0000\n",
       "28131   9.0625\n",
       "35114   7.1250\n",
       "85941   6.8125\n",
       "26819   7.1875\n",
       "...        ...\n",
       "62226   8.6250\n",
       "87904   8.5625\n",
       "32338   8.4375\n",
       "27127   8.0625\n",
       "28789   8.4375\n",
       "\n",
       "[76050 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40925</th>\n",
       "      <td>7.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46370</th>\n",
       "      <td>5.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78590</th>\n",
       "      <td>9.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101381</th>\n",
       "      <td>8.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43749</th>\n",
       "      <td>7.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88421</th>\n",
       "      <td>7.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14930</th>\n",
       "      <td>8.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>7.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>6.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85343</th>\n",
       "      <td>8.3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BWEIGHT\n",
       "40925    7.1875\n",
       "46370    5.3125\n",
       "78590    9.2500\n",
       "101381   8.1875\n",
       "43749    7.6250\n",
       "...         ...\n",
       "88421    7.1875\n",
       "14930    8.8125\n",
       "26450    7.8750\n",
       "10257    6.3125\n",
       "85343    8.3750\n",
       "\n",
       "[25350 rows x 1 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3:\n",
    "Compute mean, stdev, min, max, 25% percentile, median and 75% percentile of BWEIGHT target variable (i.e, the target y) in the training set (i.e., y_train), and print the computed values as a numpy array containing these 7 results (respectively).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original BWEIGHT              BWEIGHT\n",
      "count  101400.000000\n",
      "mean        7.258066\n",
      "std         1.329461\n",
      "min         0.187500\n",
      "25%         6.625000\n",
      "50%         7.375000\n",
      "75%         8.062500\n",
      "max        13.062500\n",
      "\n",
      "\n",
      "Trained BWEIGHT             BWEIGHT\n",
      "count  76050.000000\n",
      "mean       7.256998\n",
      "std        1.330058\n",
      "min        0.312500\n",
      "25%        6.625000\n",
      "50%        7.375000\n",
      "75%        8.062500\n",
      "max       13.062500\n",
      "\n",
      "\n",
      " [            BWEIGHT\n",
      "count  76050.000000\n",
      "mean       7.256998\n",
      "std        1.330058\n",
      "min        0.312500\n",
      "25%        6.625000\n",
      "50%        7.375000\n",
      "75%        8.062500\n",
      "max       13.062500]\n",
      "\n",
      "\n",
      " [BWEIGHT    7.256998\n",
      "dtype: float64, BWEIGHT    1.33005\n",
      "dtype: float64, BWEIGHT    0.3125\n",
      "dtype: float64, BWEIGHT    13.0625\n",
      "dtype: float64, 6.625, 7.375, 8.0625]\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "print(\"Original BWEIGHT\", y.describe())\n",
    "\n",
    "\n",
    "print(\"\\n\\nTrained BWEIGHT\", y_train.describe())\n",
    "\n",
    "#making just a general array \n",
    "arr = y_train.describe()\n",
    "values = []\n",
    "values.append(arr)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\", values)\n",
    "\n",
    "\n",
    "#making a numpy list\n",
    "emptyList = []\n",
    "mean = np.mean(y_train)\n",
    "stdev =np.std(y_train)\n",
    "minim = np.min(y_train)\n",
    "maxim = np.max(y_train)\n",
    "quarter = np.percentile(y_train,25)\n",
    "median = np.median(y_train)\n",
    "threeQuarters = np.percentile(y_train,75)\n",
    "emptyList.append(mean)\n",
    "emptyList.append(stdev)\n",
    "emptyList.append(minim)\n",
    "emptyList.append(maxim)\n",
    "emptyList.append(quarter)\n",
    "emptyList.append(median)\n",
    "emptyList.append(threeQuarters)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\", emptyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: \n",
    "Given the training dataset (X_train, y_train), save as X_train_ohe after replacing all the non-numeric variables (i.e., categorical variables) with numeric encoding. Please consider using the \"One-hot encoding\" scheme i.e., introducing dummy variables. A brief description of the scheme can be found in the [DUMMY-variables.note.txt](DUMMY-variables.note.txt) file\n",
    "* Use the same encoder to perform onehotencoding on the X_test dataset and save the result as X_test_ohe.\n",
    "* Print the column names of X_test_ohe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = X_train.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = X_train.columns[categorical_feature_mask].tolist()\n",
    "cat_columns_idx = [X_train.columns.get_loc(col) \n",
    "                   for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_cols),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = pd.DataFrame(column_trans.fit_transform(X_train),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                  0.0                  0.0                  1.0   \n",
       "1                  0.0                  0.0                  1.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  0.0                  0.0                  1.0   \n",
       "4                  0.0                  0.0                  1.0   \n",
       "\n",
       "   onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x1_N  ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  \\\n",
       "0                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1                  1.0  ...       0.0      1.0      0.0     0.0     0.0   \n",
       "2                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "3                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "4                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "\n",
       "   PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0      0.0      0.0    0.0    0.0      0.0  \n",
       "1      0.0      0.0    0.0    0.0      0.0  \n",
       "2      0.0      0.0    0.0    0.0      0.0  \n",
       "3      0.0      0.0    0.0    0.0      0.0  \n",
       "4      0.0      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ohe = pd.DataFrame(column_trans.transform(X_test),columns=column_trans.get_feature_names())\n",
    "X_test_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehotencoder__x0_C\n",
      "onehotencoder__x0_M\n",
      "onehotencoder__x0_N\n",
      "onehotencoder__x0_O\n",
      "onehotencoder__x0_P\n",
      "onehotencoder__x0_S\n",
      "onehotencoder__x0_U\n",
      "onehotencoder__x1_C\n",
      "onehotencoder__x1_M\n",
      "onehotencoder__x1_N\n",
      "onehotencoder__x1_O\n",
      "onehotencoder__x1_P\n",
      "onehotencoder__x1_S\n",
      "onehotencoder__x1_U\n",
      "SEX\n",
      "MARITAL\n",
      "FAGE\n",
      "GAINED\n",
      "VISITS\n",
      "MAGE\n",
      "FEDUC\n",
      "MEDUC\n",
      "TOTALP\n",
      "BDEAD\n",
      "TERMS\n",
      "LOUTCOME\n",
      "WEEKS\n",
      "RACEMOM\n",
      "RACEDAD\n",
      "CIGNUM\n",
      "DRINKNUM\n",
      "ANEMIA\n",
      "CARDIAC\n",
      "ACLUNG\n",
      "DIABETES\n",
      "HERPES\n",
      "HYDRAM\n",
      "HEMOGLOB\n",
      "HYPERCH\n",
      "HYPERPR\n",
      "ECLAMP\n",
      "CERVIX\n",
      "PINFANT\n",
      "PRETERM\n",
      "RENAL\n",
      "RHSEN\n",
      "UTERINE\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "for col in X_test_ohe.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: \n",
    "* Given the X_train_ohe (Onehot encoded Pandas Dataframe from Task 4), check if there are missing values, and if yes, count how many, and impute the missing values with corresponding mean values. \n",
    "* Finally, print the counting result as a Pandas dataframe named \"missing_counts\" having 2 columns {variable_name,num_of_missing_values).  Please make sure that the result lists all the input variables in the given dataset. \n",
    "* Now, impute the missing values by mean of the respective variable and save the revised dataframe as X_train_ohe_imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28493</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69082</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "28493                  0.0                  0.0                  1.0   \n",
       "58883                  0.0                  0.0                  1.0   \n",
       "65363                  0.0                  0.0                  1.0   \n",
       "69082                  0.0                  0.0                  0.0   \n",
       "73898                  0.0                  0.0                  1.0   \n",
       "\n",
       "       onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "28493                  0.0                  0.0                  0.0   \n",
       "58883                  0.0                  0.0                  0.0   \n",
       "65363                  0.0                  0.0                  0.0   \n",
       "69082                  0.0                  0.0                  1.0   \n",
       "73898                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "28493                  0.0                  0.0                  0.0   \n",
       "58883                  0.0                  0.0                  0.0   \n",
       "65363                  0.0                  0.0                  0.0   \n",
       "69082                  0.0                  0.0                  0.0   \n",
       "73898                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x1_N  ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  \\\n",
       "28493                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "58883                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "65363                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "69082                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "73898                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "\n",
       "       PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "28493      0.0      0.0    0.0    0.0      0.0  \n",
       "58883      0.0      0.0    0.0    0.0      0.0  \n",
       "65363      0.0      0.0    0.0    0.0      0.0  \n",
       "69082      0.0      0.0    0.0    0.0      0.0  \n",
       "73898      0.0      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#for column in X_train_ohe:\n",
    "    #need to append this to missing, can you just stick append to the front of it? does it make sense?\n",
    "    #missing.append(column, X_train_ohe[column].isnull().sum())\n",
    "    #print(\"{}: {}\".format(column, X_train_ohe[column].isnull().sum()))\n",
    "\n",
    "    \n",
    "#printing the whole xtrain ohe with missing values \n",
    "missing = X_train_ohe[X_train_ohe.isnull().any(axis=1)]   \n",
    "#missing = X_train_ohe.isnull().any(axis = 1).sum()\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GAINED', 'FEDUC', 'WEEKS', 'CIGNUM', 'HYDRAM'], dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the names of the ones with missing values \n",
    "X_train_ohe.columns[X_train_ohe.isnull().any()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_name        num_of_missing_values\n",
      "onehotencoder__x0_C                      0\n",
      "onehotencoder__x0_M                      0\n",
      "onehotencoder__x0_N                      0\n",
      "onehotencoder__x0_O                      0\n",
      "onehotencoder__x0_P                      0\n",
      "onehotencoder__x0_S                      0\n",
      "onehotencoder__x0_U                      0\n",
      "onehotencoder__x1_C                      0\n",
      "onehotencoder__x1_M                      0\n",
      "onehotencoder__x1_N                      0\n",
      "onehotencoder__x1_O                      0\n",
      "onehotencoder__x1_P                      0\n",
      "onehotencoder__x1_S                      0\n",
      "onehotencoder__x1_U                      0\n",
      "SEX                                      0\n",
      "MARITAL                                  0\n",
      "FAGE                                     0\n",
      "GAINED                                   1\n",
      "VISITS                                   0\n",
      "MAGE                                     0\n",
      "FEDUC                                    1\n",
      "MEDUC                                    0\n",
      "TOTALP                                   0\n",
      "BDEAD                                    0\n",
      "TERMS                                    0\n",
      "LOUTCOME                                 0\n",
      "WEEKS                                    1\n",
      "RACEMOM                                  0\n",
      "RACEDAD                                  0\n",
      "CIGNUM                                   1\n",
      "DRINKNUM                                 0\n",
      "ANEMIA                                   0\n",
      "CARDIAC                                  0\n",
      "ACLUNG                                   0\n",
      "DIABETES                                 0\n",
      "HERPES                                   0\n",
      "HYDRAM                                   1\n",
      "HEMOGLOB                                 0\n",
      "HYPERCH                                  0\n",
      "HYPERPR                                  0\n",
      "ECLAMP                                   0\n",
      "CERVIX                                   0\n",
      "PINFANT                                  0\n",
      "PRETERM                                  0\n",
      "RENAL                                    0\n",
      "RHSEN                                    0\n",
      "UTERINE                                  0\n"
     ]
    }
   ],
   "source": [
    "#we see that gained, feduc, weeks, cignum, hydram have missing values\n",
    "#replace isnull with mean()\n",
    "#i want to take the column name in missing and stick it into the rows of variable names\n",
    "#then take the sum of missing values and put it in the rows of missing values \n",
    "    \n",
    "newSet = X_train_ohe.copy()\n",
    "missing_count = pd.DataFrame(newSet.isnull().sum()).rename_axis(\"variable_name\", axis = 1)\n",
    "missing_count.rename(columns = {0: \"num_of_missing_values\"}, inplace = True)\n",
    "\n",
    "print(missing_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                      0.0                  0.0                  1.0   \n",
       "1                      0.0                  0.0                  1.0   \n",
       "2                      0.0                  0.0                  1.0   \n",
       "3                      0.0                  0.0                  1.0   \n",
       "4                      0.0                  0.0                  1.0   \n",
       "...                    ...                  ...                  ...   \n",
       "76045                  0.0                  0.0                  1.0   \n",
       "76046                  0.0                  0.0                  1.0   \n",
       "76047                  0.0                  0.0                  1.0   \n",
       "76048                  0.0                  0.0                  1.0   \n",
       "76049                  0.0                  0.0                  1.0   \n",
       "\n",
       "       onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "76045                  0.0                  0.0                  0.0   \n",
       "76046                  0.0                  0.0                  0.0   \n",
       "76047                  0.0                  0.0                  0.0   \n",
       "76048                  0.0                  0.0                  0.0   \n",
       "76049                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "76045                  0.0                  0.0                  0.0   \n",
       "76046                  0.0                  0.0                  0.0   \n",
       "76047                  0.0                  0.0                  0.0   \n",
       "76048                  0.0                  0.0                  0.0   \n",
       "76049                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x1_N  ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  \\\n",
       "0                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "2                      1.0  ...       0.0      0.0      1.0     0.0     0.0   \n",
       "3                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "4                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "...                    ...  ...       ...      ...      ...     ...     ...   \n",
       "76045                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "76046                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "76047                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "76048                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "76049                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "\n",
       "       PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0          1.0      0.0    0.0    0.0      0.0  \n",
       "1          0.0      0.0    0.0    0.0      0.0  \n",
       "2          0.0      0.0    0.0    0.0      0.0  \n",
       "3          0.0      0.0    0.0    0.0      0.0  \n",
       "4          0.0      0.0    0.0    0.0      0.0  \n",
       "...        ...      ...    ...    ...      ...  \n",
       "76045      0.0      0.0    0.0    0.0      0.0  \n",
       "76046      0.0      0.0    0.0    0.0      0.0  \n",
       "76047      0.0      0.0    0.0    0.0      0.0  \n",
       "76048      0.0      0.0    0.0    0.0      0.0  \n",
       "76049      0.0      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[76050 rows x 47 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing the missing values with .mean()\n",
    "#bummer simpleimputer just gives me back \"SimpleImputer\"\n",
    "#X_train_ohe = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "X_train_ohe_imputed = X_train_ohe.fillna(X_train_ohe.mean())\n",
    "X_train_ohe_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure that it is empty\n",
    "X_train_ohe_imputed.columns[X_train_ohe_imputed.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: \n",
    "* Given a X_train_ohe_imputed (Pandas dataframe from Task 5) where all the categorical variables are already replaced with numeric values, print a list of top 20 highly correlated variables with respect to the target variable, and save the result as a Pandas dataframe named top20_df with 2 columns {variable,corr_score}. \n",
    "* Here, the corr_score between a variable x and the target variable y needs to be computed using the Pearson Correlation Coefficient (PCC). Please note, PCC ranges between -1 to +1. PCC score 0 means no correlation, while value towards +1 and -1 represent positive and negative correlations respectively. For instance, PCC=0.8 and PCC=-0.8 tell similar strength positive and negative correlations between the two subject variables.\n",
    "* Please do not include BWEIGHT in the top20_df list of top 20 correlated variable list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['onehotencoder__x0_C', 'onehotencoder__x0_M', 'onehotencoder__x0_N', 'onehotencoder__x0_O', 'onehotencoder__x0_P', 'onehotencoder__x0_S', 'onehotencoder__x0_U', 'onehotencoder__x1_C', 'onehotencoder__x1_M', 'onehotencoder__x1_N', 'onehotencoder__x1_O', 'onehotencoder__x1_P', 'onehotencoder__x1_S', 'onehotencoder__x1_U', 'SEX', 'MARITAL', 'FAGE', 'GAINED', 'VISITS', 'MAGE', 'FEDUC', 'MEDUC', 'TOTALP', 'BDEAD', 'TERMS', 'LOUTCOME', 'WEEKS', 'RACEMOM', 'RACEDAD', 'CIGNUM', 'DRINKNUM', 'ANEMIA', 'CARDIAC', 'ACLUNG', 'DIABETES', 'HERPES', 'HYDRAM', 'HEMOGLOB', 'HYPERCH', 'HYPERPR', 'ECLAMP', 'CERVIX', 'PINFANT', 'PRETERM', 'RENAL', 'RHSEN', 'UTERINE']\n"
     ]
    }
   ],
   "source": [
    "#save column names \n",
    "column = []\n",
    "for col in X_train_ohe.columns:\n",
    "    column.append(col)\n",
    "#convert to pd series to add together\n",
    "columnSeries = pd.Series(column) \n",
    "print(type(column))\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Corr Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CARDIAC</td>\n",
       "      <td>0.011286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CERVIX</td>\n",
       "      <td>0.010087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GAINED</td>\n",
       "      <td>-0.008894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>onehotencoder__x1_S</td>\n",
       "      <td>0.008514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TERMS</td>\n",
       "      <td>-0.008055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BDEAD</td>\n",
       "      <td>-0.007951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TOTALP</td>\n",
       "      <td>-0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HYDRAM</td>\n",
       "      <td>-0.007007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>onehotencoder__x1_N</td>\n",
       "      <td>-0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MAGE</td>\n",
       "      <td>-0.006278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>onehotencoder__x1_O</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HERPES</td>\n",
       "      <td>-0.006062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FEDUC</td>\n",
       "      <td>-0.005683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACLUNG</td>\n",
       "      <td>-0.005537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RACEDAD</td>\n",
       "      <td>0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RACEMOM</td>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onehotencoder__x0_O</td>\n",
       "      <td>0.005264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VISITS</td>\n",
       "      <td>-0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PINFANT</td>\n",
       "      <td>-0.004799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>UTERINE</td>\n",
       "      <td>-0.004468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Variable  Corr Score\n",
       "32              CARDIAC    0.011286\n",
       "41               CERVIX    0.010087\n",
       "17               GAINED   -0.008894\n",
       "12  onehotencoder__x1_S    0.008514\n",
       "24                TERMS   -0.008055\n",
       "23                BDEAD   -0.007951\n",
       "22               TOTALP   -0.007463\n",
       "36               HYDRAM   -0.007007\n",
       "9   onehotencoder__x1_N   -0.006962\n",
       "19                 MAGE   -0.006278\n",
       "10  onehotencoder__x1_O    0.006191\n",
       "35               HERPES   -0.006062\n",
       "20                FEDUC   -0.005683\n",
       "33               ACLUNG   -0.005537\n",
       "28              RACEDAD    0.005357\n",
       "27              RACEMOM    0.005348\n",
       "3   onehotencoder__x0_O    0.005264\n",
       "18               VISITS   -0.005204\n",
       "42              PINFANT   -0.004799\n",
       "46              UTERINE   -0.004468"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#y train or y test? or y? -easy adjustment if otherwise \n",
    "#we want to corrwith between imputed and target variable y\n",
    "\n",
    "corr_score = pd.DataFrame()\n",
    "\n",
    "#pearson method\n",
    "corr_score = X_train_ohe_imputed.corrwith(y_train[\"BWEIGHT\"] , axis=0, drop=True, method='pearson')\n",
    "\n",
    "#naming the columns \n",
    "corr_score = corr_score.rename_axis(\"Variable\").reset_index()\n",
    "corr_score.rename(columns={ corr_score.columns[1]: \"Corr Score\" }, inplace = True)\n",
    "\n",
    "#sorting by the abs of corr score and taking top 20 in two columns \n",
    "top20 = corr_score.sort_values(by = \"Corr Score\", ascending = False, key = abs).iloc[:20]\n",
    "top20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGNORE THIS ENTIRE CELL. KEEPING IT FOR MY OWN REFERENCE\n"
     ]
    }
   ],
   "source": [
    "print(\"IGNORE THIS ENTIRE CELL. KEEPING IT FOR MY OWN REFERENCE\")\n",
    "\n",
    "# #@TODO: Your code goes here\n",
    "\n",
    "# #y train or y test? or y? - just y lol \n",
    "# #we want to corrwith between imputed and target variable y\n",
    "\n",
    "# corr_score = pd.DataFrame()\n",
    "\n",
    "# corr_score = X_train_ohe_imputed.corrwith(y_train[\"BWEIGHT\"] , axis=0, drop=True, method='pearson')\n",
    "# corr_score = corr_score.rename_axis(\"Variable\").reset_index()\n",
    "# corr_score.rename(columns={ corr_score.columns[1]: \"Corr Score\" }, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# ######################################################################## leave this top part alone\n",
    "\n",
    "# #corr_score.to_frame().T\n",
    "# # index = corr_score.index\n",
    "# # print(index, \"\\n\\n\")\n",
    "\n",
    "\n",
    "# #########################THIS IS THE BULLSHIT TO FIGURE OUT HOW TO NAME COLUMNS\n",
    "# #this line is to convert index to column name. Somehow not working \n",
    "# #corr_score['variable'] = corr_score.index\n",
    "# #corr_score = corr_score.reset_index(drop = True)\n",
    "\n",
    "# #corr_score= corr_score.to_frame().T\n",
    "\n",
    "# #corr_score.assign(State=corr_score.index.get_level_values('Variable'))\n",
    "\n",
    "# #corr_score = pd.concat([pd.Series(columnSeries), corr_score], axis=1)\n",
    "# #\n",
    "# #the index that i have for the column doesn't exist - get the titles of columns as a list and append them to corr_score \n",
    "\n",
    "\n",
    "# # newSet = X_train_ohe.copy()\n",
    "# # missing_count = pd.DataFrame(newSet.isnull().sum()).rename_axis(\"variable_name\", axis = 1)\n",
    "# # missing_count.rename(columns = {0: \"num_of_missing_values\"}, inplace = True)\n",
    "\n",
    "\n",
    "# #corr_score.rename(columns = {1: \"corr_score\"}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# ################################################################END BULLSHIT \n",
    "# print(corr_score.shape)\n",
    "# print(type(corr_score))\n",
    "# print(corr_score)\n",
    "\n",
    "# #top20=pd.DataFrame(top20,columns=['variable' , 'corr_score'])\n",
    "\n",
    "# #need absolute values of pearsons correlation\n",
    "# #corr_score = corr_score[\"Corr Score\"].abs()\n",
    "# top20 = corr_score.sort_values(by = \"Corr Score\", ascending = False, key = abs).iloc[:20]\n",
    "# top20 \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7: \n",
    "Given the X_train_ohe_imputed (as Pandas dataframe from task 5) and and top20_df (as Pandas Dataframe from Task 6) having 2 columns {variable_name,corr_score} similar to the one you computed in Task 6:\n",
    "* Please save as X_train_t20 keeping only the columns listed in the top20_df dataframe.\n",
    "* Repeat the process for X_test_ohe (obtained from task 4), and save it as X_test_t20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@TODO: Your code goes here\n",
    "# #is this all?? This question was so hard to understand \n",
    "# #jk scroll down \n",
    "\n",
    "# #keeping only the columns listed?\n",
    "# #from top20\n",
    "# X_train_t20 = []\n",
    "# for col in top20.iterrows():\n",
    "#     if any(col ):\n",
    "#         X_train_t20.append(col)\n",
    "# X_train_t20\n",
    "\n",
    "# #ohe imputed\n",
    "# Xtest20List = column\n",
    "# Xtest20List = Xtest20List[:20]\n",
    "\n",
    "\n",
    "\n",
    "# # XTrain20 = x_test_ohe_imputed.iloc[0, 0:20].copy()\n",
    "# # XTrain20\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CARDIAC  CERVIX  GAINED  onehotencoder__x1_S  TERMS  BDEAD  TOTALP  \\\n",
       "0          0.0     0.0    50.0                  0.0    0.0    0.0     3.0   \n",
       "1          0.0     0.0    50.0                  0.0    0.0    0.0     2.0   \n",
       "2          0.0     0.0    38.0                  0.0    0.0    0.0     1.0   \n",
       "3          0.0     0.0    20.0                  0.0    0.0    0.0     1.0   \n",
       "4          0.0     0.0    30.0                  0.0    0.0    0.0     3.0   \n",
       "...        ...     ...     ...                  ...    ...    ...     ...   \n",
       "76045      0.0     0.0    51.0                  0.0    0.0    0.0     1.0   \n",
       "76046      0.0     0.0    38.0                  0.0    1.0    0.0     5.0   \n",
       "76047      0.0     0.0    30.0                  0.0    0.0    0.0     2.0   \n",
       "76048      0.0     0.0    23.0                  0.0    0.0    0.0     2.0   \n",
       "76049      0.0     0.0    24.0                  0.0    0.0    0.0     2.0   \n",
       "\n",
       "       HYDRAM  onehotencoder__x1_N  MAGE  onehotencoder__x1_O  HERPES  FEDUC  \\\n",
       "0         0.0                  1.0  32.0                  0.0     0.0   12.0   \n",
       "1         0.0                  1.0  20.0                  0.0     0.0   12.0   \n",
       "2         0.0                  1.0  21.0                  0.0     0.0   12.0   \n",
       "3         0.0                  1.0  19.0                  0.0     0.0   12.0   \n",
       "4         0.0                  1.0  30.0                  0.0     0.0   16.0   \n",
       "...       ...                  ...   ...                  ...     ...    ...   \n",
       "76045     0.0                  1.0  18.0                  0.0     0.0   12.0   \n",
       "76046     0.0                  1.0  27.0                  0.0     0.0    9.0   \n",
       "76047     0.0                  1.0  31.0                  0.0     0.0   14.0   \n",
       "76048     0.0                  1.0  37.0                  0.0     0.0   12.0   \n",
       "76049     0.0                  1.0  31.0                  0.0     0.0   17.0   \n",
       "\n",
       "       ACLUNG  RACEDAD  RACEMOM  onehotencoder__x0_O  VISITS  PINFANT  UTERINE  \n",
       "0         0.0      1.0      1.0                  0.0    16.0      1.0      0.0  \n",
       "1         0.0      2.0      2.0                  0.0    13.0      0.0      0.0  \n",
       "2         0.0      1.0      1.0                  0.0    11.0      0.0      0.0  \n",
       "3         0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "4         0.0      1.0      1.0                  0.0    13.0      0.0      0.0  \n",
       "...       ...      ...      ...                  ...     ...      ...      ...  \n",
       "76045     0.0      1.0      1.0                  0.0    18.0      0.0      0.0  \n",
       "76046     0.0      1.0      1.0                  0.0     4.0      0.0      0.0  \n",
       "76047     0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "76048     0.0      1.0      1.0                  0.0    13.0      0.0      0.0  \n",
       "76049     0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "\n",
       "[76050 rows x 20 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so if the columns in xtrain ohe exist in top20, then we want to keep the xtrain columns \n",
    "#make a list of top20 columns\n",
    "#compare that list to xtrain imputed columns\n",
    "\n",
    "colList = top20[\"Variable\"].tolist()\n",
    "#coList\n",
    "#df2 = X_train_ohe_imputed.filter(regex=colList)\n",
    "#X_train_ohe_imputed= X_train_ohe_imputed.loc[:,X_train_ohe_imputed.columns.isin([colList])]\n",
    "\n",
    "\n",
    "#in the essence of time, sorry for hardcoding it. \n",
    "# X_train_ohe_imputed = X_train_ohe_imputed[X_train_ohe_imputed.columns[X_train_ohe_imputed.columns.isin(['CARDIAC',\n",
    "#  'CERVIX',\n",
    "#  'GAINED',\n",
    "#  'onehotencoder__x1_S',\n",
    "#  'TERMS',\n",
    "#  'BDEAD',\n",
    "#  'TOTALP',\n",
    "#  'HYDRAM',\n",
    "#  'onehotencoder__x1_N',\n",
    "#  'MAGE',\n",
    "#  'onehotencoder__x1_O',\n",
    "#  'HERPES',\n",
    "#  'FEDUC',\n",
    "#  'ACLUNG',\n",
    "#  'RACEDAD',\n",
    "#  'RACEMOM',\n",
    "#  'onehotencoder__x0_O',\n",
    "#  'VISITS',\n",
    "#  'PINFANT',\n",
    "#  'UTERINE'])]]\n",
    "\n",
    "tList = [i for i in top20[\"Variable\"].values]\n",
    "\n",
    "X_train_ohe_imputed =  X_train_ohe_imputed.loc[:,tList]\n",
    "\n",
    "X_train_ohe_imputed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this way doesn't work \n",
    "\n",
    "# def goddammit(top20, X_train_ohe_imputed):\n",
    "#     stupid =[]\n",
    "    \n",
    "#     for index in top20.iterrows():\n",
    "#         stupid.append(index[0])\n",
    "    \n",
    "#     t20 = pd.DataFrame(X_train_ohe_imputed, columns = stupid)\n",
    "    \n",
    "#     return t20\n",
    "\n",
    "\n",
    "# xtrain20 = goddammit(top20, X_train_ohe_imputed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                      0.0                  0.0                  1.0   \n",
       "1                      0.0                  0.0                  1.0   \n",
       "2                      0.0                  0.0                  1.0   \n",
       "3                      0.0                  0.0                  1.0   \n",
       "4                      0.0                  0.0                  1.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  1.0   \n",
       "25346                  0.0                  1.0                  0.0   \n",
       "25347                  0.0                  1.0                  0.0   \n",
       "25348                  0.0                  0.0                  1.0   \n",
       "25349                  0.0                  0.0                  1.0   \n",
       "\n",
       "       onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  0.0   \n",
       "25346                  0.0                  0.0                  0.0   \n",
       "25347                  0.0                  0.0                  0.0   \n",
       "25348                  0.0                  0.0                  0.0   \n",
       "25349                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  0.0   \n",
       "25346                  0.0                  0.0                  1.0   \n",
       "25347                  0.0                  0.0                  1.0   \n",
       "25348                  0.0                  0.0                  0.0   \n",
       "25349                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x1_N  ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  \\\n",
       "0                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1                      1.0  ...       0.0      1.0      0.0     0.0     0.0   \n",
       "2                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "3                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "4                      1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "...                    ...  ...       ...      ...      ...     ...     ...   \n",
       "25345                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "25346                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "25347                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "25348                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "25349                  1.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "\n",
       "       PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0          0.0      0.0    0.0    0.0      0.0  \n",
       "1          0.0      0.0    0.0    0.0      0.0  \n",
       "2          0.0      0.0    0.0    0.0      0.0  \n",
       "3          0.0      0.0    0.0    0.0      0.0  \n",
       "4          0.0      0.0    0.0    0.0      0.0  \n",
       "...        ...      ...    ...    ...      ...  \n",
       "25345      0.0      0.0    0.0    0.0      0.0  \n",
       "25346      0.0      0.0    0.0    0.0      0.0  \n",
       "25347      0.0      0.0    0.0    0.0      0.0  \n",
       "25348      0.0      0.0    0.0    0.0      0.0  \n",
       "25349      0.0      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[25350 rows x 47 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XTEST OHE #5\n",
    "\n",
    "\n",
    "missingOHE = X_train_ohe[X_train_ohe.isnull().any(axis=1)]   \n",
    "X_test_ohe.columns[X_test_ohe.isnull().any()]\n",
    "\n",
    "x_test_ohe_imputed = X_test_ohe.copy()\n",
    "missingOHE  = pd.DataFrame(newSet.isnull().sum()).rename_axis(\"variable_name\", axis = 1)\n",
    "missingOHE.rename(columns = {0: \"num_of_missing_values\"}, inplace = True)\n",
    "X_test_ohe_imputed = X_test_ohe.fillna(X_test_ohe.mean())\n",
    "x_test_ohe_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Corr Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RHSEN</td>\n",
       "      <td>-0.013462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>onehotencoder__x1_U</td>\n",
       "      <td>-0.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VISITS</td>\n",
       "      <td>0.011618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onehotencoder__x0_O</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MEDUC</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BDEAD</td>\n",
       "      <td>-0.010919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HYPERCH</td>\n",
       "      <td>-0.008974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onehotencoder__x0_S</td>\n",
       "      <td>0.008924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HYDRAM</td>\n",
       "      <td>0.008724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>onehotencoder__x1_O</td>\n",
       "      <td>0.008716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HEMOGLOB</td>\n",
       "      <td>-0.007996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ANEMIA</td>\n",
       "      <td>-0.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>onehotencoder__x1_C</td>\n",
       "      <td>-0.006429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HERPES</td>\n",
       "      <td>-0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MAGE</td>\n",
       "      <td>0.006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GAINED</td>\n",
       "      <td>0.005771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PRETERM</td>\n",
       "      <td>0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WEEKS</td>\n",
       "      <td>0.005621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onehotencoder__x0_U</td>\n",
       "      <td>-0.005475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FEDUC</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Variable  Corr Score\n",
       "45                RHSEN   -0.013462\n",
       "13  onehotencoder__x1_U   -0.011783\n",
       "18               VISITS    0.011618\n",
       "3   onehotencoder__x0_O    0.011248\n",
       "21                MEDUC    0.011090\n",
       "23                BDEAD   -0.010919\n",
       "38              HYPERCH   -0.008974\n",
       "5   onehotencoder__x0_S    0.008924\n",
       "36               HYDRAM    0.008724\n",
       "10  onehotencoder__x1_O    0.008716\n",
       "37             HEMOGLOB   -0.007996\n",
       "31               ANEMIA   -0.007880\n",
       "7   onehotencoder__x1_C   -0.006429\n",
       "35               HERPES   -0.006150\n",
       "19                 MAGE    0.006029\n",
       "17               GAINED    0.005771\n",
       "43              PRETERM    0.005730\n",
       "26                WEEKS    0.005621\n",
       "6   onehotencoder__x0_U   -0.005475\n",
       "20                FEDUC    0.004658"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XTEST OHE 6\n",
    "\n",
    "testOHE = pd.DataFrame()\n",
    "\n",
    "#pearson method\n",
    "testOHE = X_test_ohe_imputed.corrwith(y_train[\"BWEIGHT\"] , axis=0, drop=True, method='pearson')\n",
    "\n",
    "#naming the columns \n",
    "testOHE = testOHE.rename_axis(\"Variable\").reset_index()\n",
    "testOHE.rename(columns={testOHE.columns[1]: \"Corr Score\" }, inplace = True)\n",
    "\n",
    "#sorting by the abs of corr score and taking top 20 in two columns \n",
    "top20OHE = testOHE.sort_values(by = \"Corr Score\", ascending = False, key = abs).iloc[:20]\n",
    "top20OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>FEDUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RHSEN  onehotencoder__x1_U  VISITS  onehotencoder__x0_O  MEDUC  BDEAD  \\\n",
       "0        0.0                  0.0    16.0                  0.0   17.0    0.0   \n",
       "1        0.0                  0.0    10.0                  0.0   15.0    0.0   \n",
       "2        0.0                  0.0    12.0                  0.0   14.0    0.0   \n",
       "3        0.0                  0.0    15.0                  0.0   13.0    0.0   \n",
       "4        0.0                  0.0     7.0                  0.0   16.0    0.0   \n",
       "...      ...                  ...     ...                  ...    ...    ...   \n",
       "25345    0.0                  0.0     8.0                  0.0   14.0    0.0   \n",
       "25346    0.0                  0.0    12.0                  0.0    6.0    0.0   \n",
       "25347    0.0                  0.0     3.0                  0.0   10.0    0.0   \n",
       "25348    0.0                  0.0    10.0                  0.0   17.0    0.0   \n",
       "25349    0.0                  0.0    12.0                  0.0   17.0    0.0   \n",
       "\n",
       "       HYPERCH  onehotencoder__x0_S  HYDRAM  onehotencoder__x1_O  HEMOGLOB  \\\n",
       "0          0.0                  0.0     0.0                  0.0       0.0   \n",
       "1          1.0                  0.0     0.0                  0.0       0.0   \n",
       "2          0.0                  0.0     0.0                  0.0       0.0   \n",
       "3          0.0                  0.0     0.0                  0.0       0.0   \n",
       "4          0.0                  0.0     0.0                  0.0       0.0   \n",
       "...        ...                  ...     ...                  ...       ...   \n",
       "25345      0.0                  0.0     0.0                  0.0       0.0   \n",
       "25346      0.0                  0.0     0.0                  0.0       0.0   \n",
       "25347      0.0                  0.0     0.0                  0.0       0.0   \n",
       "25348      0.0                  0.0     0.0                  0.0       0.0   \n",
       "25349      0.0                  0.0     0.0                  0.0       0.0   \n",
       "\n",
       "       ANEMIA  onehotencoder__x1_C  HERPES  MAGE  GAINED  PRETERM  WEEKS  \\\n",
       "0         0.0                  0.0     0.0  29.0    33.0      0.0   39.0   \n",
       "1         0.0                  0.0     0.0  22.0    20.0      0.0   39.0   \n",
       "2         0.0                  0.0     0.0  21.0    34.0      0.0   38.0   \n",
       "3         0.0                  0.0     0.0  28.0    16.0      0.0   39.0   \n",
       "4         1.0                  0.0     0.0  30.0    30.0      0.0   39.0   \n",
       "...       ...                  ...     ...   ...     ...      ...    ...   \n",
       "25345     0.0                  0.0     0.0  27.0     0.0      0.0   40.0   \n",
       "25346     0.0                  0.0     0.0  29.0    30.0      0.0   39.0   \n",
       "25347     0.0                  0.0     0.0  34.0    28.0      0.0   41.0   \n",
       "25348     0.0                  0.0     0.0  39.0    29.0      0.0   36.0   \n",
       "25349     0.0                  0.0     0.0  37.0    30.0      0.0   38.0   \n",
       "\n",
       "       onehotencoder__x0_U  FEDUC  \n",
       "0                      0.0   16.0  \n",
       "1                      0.0   12.0  \n",
       "2                      0.0   10.0  \n",
       "3                      0.0   12.0  \n",
       "4                      0.0   16.0  \n",
       "...                    ...    ...  \n",
       "25345                  0.0   13.0  \n",
       "25346                  0.0    8.0  \n",
       "25347                  0.0   10.0  \n",
       "25348                  0.0   17.0  \n",
       "25349                  0.0   16.0  \n",
       "\n",
       "[25350 rows x 20 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheList = top20OHE[\"Variable\"].tolist()\n",
    "oheList\n",
    "#df2 = X_train_ohe_imputed.filter(regex=colList)\n",
    "#X_train_ohe_imputed= X_train_ohe_imputed.loc[:,X_train_ohe_imputed.columns.isin([colList])]\n",
    "\n",
    "\n",
    "#in the essence of time, sorry for hardcoding it. \n",
    "# xTestOHE20 = x_test_ohe_imputed[x_test_ohe_imputed.columns[x_test_ohe_imputed.columns.isin(['RHSEN',\n",
    "#  'onehotencoder__x1_U',\n",
    "#  'VISITS',\n",
    "#  'onehotencoder__x0_O',\n",
    "#  'MEDUC',\n",
    "#  'BDEAD',\n",
    "#  'HYPERCH',\n",
    "#  'onehotencoder__x0_S',\n",
    "#  'HYDRAM',\n",
    "#  'onehotencoder__x1_O',\n",
    "#  'HEMOGLOB',\n",
    "#  'ANEMIA',\n",
    "#  'onehotencoder__x1_C',\n",
    "#  'HERPES',\n",
    "#  'MAGE',\n",
    "#  'GAINED',\n",
    "#  'PRETERM',\n",
    "#  'WEEKS',\n",
    "#  'onehotencoder__x0_U',\n",
    "#  'FEDUC'])]]\n",
    "\n",
    "\n",
    "testList = [i for i in top20OHE[\"Variable\"].values]\n",
    "\n",
    "xTestOHE20  =  x_test_ohe_imputed.loc[:,testList]\n",
    "\n",
    "xTestOHE20 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please save as X_train_t20 keeping only the columns listed in the top20_df dataframe.  \n",
    "Repeat the process for X_test_ohe (obtained from task 4), and save it as X_test_t20.  \n",
    "\n",
    "saving the df as new df and only keeping 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBO OF THE TWO FOR EASY TO READ\n",
    "\n",
    "xTrainTop20 = X_train_ohe_imputed.copy()\n",
    "X_test_t20 = xTestOHE20.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CARDIAC  CERVIX  GAINED  onehotencoder__x1_S  TERMS  BDEAD  TOTALP  \\\n",
       "0          0.0     0.0    50.0                  0.0    0.0    0.0     3.0   \n",
       "1          0.0     0.0    50.0                  0.0    0.0    0.0     2.0   \n",
       "2          0.0     0.0    38.0                  0.0    0.0    0.0     1.0   \n",
       "3          0.0     0.0    20.0                  0.0    0.0    0.0     1.0   \n",
       "4          0.0     0.0    30.0                  0.0    0.0    0.0     3.0   \n",
       "...        ...     ...     ...                  ...    ...    ...     ...   \n",
       "76045      0.0     0.0    51.0                  0.0    0.0    0.0     1.0   \n",
       "76046      0.0     0.0    38.0                  0.0    1.0    0.0     5.0   \n",
       "76047      0.0     0.0    30.0                  0.0    0.0    0.0     2.0   \n",
       "76048      0.0     0.0    23.0                  0.0    0.0    0.0     2.0   \n",
       "76049      0.0     0.0    24.0                  0.0    0.0    0.0     2.0   \n",
       "\n",
       "       HYDRAM  onehotencoder__x1_N  MAGE  onehotencoder__x1_O  HERPES  FEDUC  \\\n",
       "0         0.0                  1.0  32.0                  0.0     0.0   12.0   \n",
       "1         0.0                  1.0  20.0                  0.0     0.0   12.0   \n",
       "2         0.0                  1.0  21.0                  0.0     0.0   12.0   \n",
       "3         0.0                  1.0  19.0                  0.0     0.0   12.0   \n",
       "4         0.0                  1.0  30.0                  0.0     0.0   16.0   \n",
       "...       ...                  ...   ...                  ...     ...    ...   \n",
       "76045     0.0                  1.0  18.0                  0.0     0.0   12.0   \n",
       "76046     0.0                  1.0  27.0                  0.0     0.0    9.0   \n",
       "76047     0.0                  1.0  31.0                  0.0     0.0   14.0   \n",
       "76048     0.0                  1.0  37.0                  0.0     0.0   12.0   \n",
       "76049     0.0                  1.0  31.0                  0.0     0.0   17.0   \n",
       "\n",
       "       ACLUNG  RACEDAD  RACEMOM  onehotencoder__x0_O  VISITS  PINFANT  UTERINE  \n",
       "0         0.0      1.0      1.0                  0.0    16.0      1.0      0.0  \n",
       "1         0.0      2.0      2.0                  0.0    13.0      0.0      0.0  \n",
       "2         0.0      1.0      1.0                  0.0    11.0      0.0      0.0  \n",
       "3         0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "4         0.0      1.0      1.0                  0.0    13.0      0.0      0.0  \n",
       "...       ...      ...      ...                  ...     ...      ...      ...  \n",
       "76045     0.0      1.0      1.0                  0.0    18.0      0.0      0.0  \n",
       "76046     0.0      1.0      1.0                  0.0     4.0      0.0      0.0  \n",
       "76047     0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "76048     0.0      1.0      1.0                  0.0    13.0      0.0      0.0  \n",
       "76049     0.0      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "\n",
       "[76050 rows x 20 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainTop20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 8: \n",
    "* Apply min-max scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_mm.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_mm.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.275510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CARDIAC  CERVIX    GAINED  onehotencoder__x1_S     TERMS  BDEAD  \\\n",
       "0          0.0     0.0  0.510204                  0.0  0.000000    0.0   \n",
       "1          0.0     0.0  0.510204                  0.0  0.000000    0.0   \n",
       "2          0.0     0.0  0.387755                  0.0  0.000000    0.0   \n",
       "3          0.0     0.0  0.204082                  0.0  0.000000    0.0   \n",
       "4          0.0     0.0  0.306122                  0.0  0.000000    0.0   \n",
       "...        ...     ...       ...                  ...       ...    ...   \n",
       "76045      0.0     0.0  0.520408                  0.0  0.000000    0.0   \n",
       "76046      0.0     0.0  0.387755                  0.0  0.010204    0.0   \n",
       "76047      0.0     0.0  0.306122                  0.0  0.000000    0.0   \n",
       "76048      0.0     0.0  0.234694                  0.0  0.000000    0.0   \n",
       "76049      0.0     0.0  0.244898                  0.0  0.000000    0.0   \n",
       "\n",
       "         TOTALP  HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0      0.030612     0.0             0.010204  0.326531                  0.0   \n",
       "1      0.020408     0.0             0.010204  0.204082                  0.0   \n",
       "2      0.010204     0.0             0.010204  0.214286                  0.0   \n",
       "3      0.010204     0.0             0.010204  0.193878                  0.0   \n",
       "4      0.030612     0.0             0.010204  0.306122                  0.0   \n",
       "...         ...     ...                  ...       ...                  ...   \n",
       "76045  0.010204     0.0             0.010204  0.183673                  0.0   \n",
       "76046  0.051020     0.0             0.010204  0.275510                  0.0   \n",
       "76047  0.020408     0.0             0.010204  0.316327                  0.0   \n",
       "76048  0.020408     0.0             0.010204  0.377551                  0.0   \n",
       "76049  0.020408     0.0             0.010204  0.316327                  0.0   \n",
       "\n",
       "       HERPES     FEDUC  ACLUNG   RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0         0.0  0.122449     0.0  0.010204  0.010204                  0.0   \n",
       "1         0.0  0.122449     0.0  0.020408  0.020408                  0.0   \n",
       "2         0.0  0.122449     0.0  0.010204  0.010204                  0.0   \n",
       "3         0.0  0.122449     0.0  0.010204  0.010204                  0.0   \n",
       "4         0.0  0.163265     0.0  0.010204  0.010204                  0.0   \n",
       "...       ...       ...     ...       ...       ...                  ...   \n",
       "76045     0.0  0.122449     0.0  0.010204  0.010204                  0.0   \n",
       "76046     0.0  0.091837     0.0  0.010204  0.010204                  0.0   \n",
       "76047     0.0  0.142857     0.0  0.010204  0.010204                  0.0   \n",
       "76048     0.0  0.122449     0.0  0.010204  0.010204                  0.0   \n",
       "76049     0.0  0.173469     0.0  0.010204  0.010204                  0.0   \n",
       "\n",
       "         VISITS   PINFANT  UTERINE  \n",
       "0      0.163265  0.010204      0.0  \n",
       "1      0.132653  0.000000      0.0  \n",
       "2      0.112245  0.000000      0.0  \n",
       "3      0.102041  0.000000      0.0  \n",
       "4      0.132653  0.000000      0.0  \n",
       "...         ...       ...      ...  \n",
       "76045  0.183673  0.000000      0.0  \n",
       "76046  0.040816  0.000000      0.0  \n",
       "76047  0.102041  0.000000      0.0  \n",
       "76048  0.132653  0.000000      0.0  \n",
       "76049  0.102041  0.000000      0.0  \n",
       "\n",
       "[76050 rows x 20 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "# TRAINING SCALE - using built in libraries  \n",
    "#https://stackoverflow.com/questions/66809458/minmaxscaler-with-range-from-multiple-columns-in-dataframe\n",
    "#don't even need built in libraries \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "xtrainScale = xTrainTop20.copy()\n",
    "# xtrainList = xtrainScale.values.astype(float).reshape(-1,1)\n",
    "\n",
    "# trainScaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# X_train_scaled_mm = trainScaler.fit_transform(xtrainList)\n",
    "# print(type(X_train_scaled_mm))\n",
    "# xtrainScale[\"Corr Score\"] = X_train_scaled_mm\n",
    "\n",
    "# X_train_scaled_mm = xtrainScale\n",
    "# #X_train_scaled_mm.rename(columns={X_train_scaled_mm.columns[1]: \"Scaled Values\" }, inplace = True)\n",
    "\n",
    "\n",
    "# X_train_scaled_mm.head()\n",
    "\n",
    "minus = xtrainScale.min().min()    \n",
    "maxas = xtrainScale.max().max()    \n",
    "X_test_scaled_mm = (xtrainScale - minus) / (maxas - minus)\n",
    "X_test_scaled_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CARDIAC  CERVIX    GAINED  onehotencoder__x1_S     TERMS  BDEAD  \\\n",
       "0          0.0     0.0  0.005206                  0.0  0.000000    0.0   \n",
       "1          0.0     0.0  0.005206                  0.0  0.000000    0.0   \n",
       "2          0.0     0.0  0.003957                  0.0  0.000000    0.0   \n",
       "3          0.0     0.0  0.002082                  0.0  0.000000    0.0   \n",
       "4          0.0     0.0  0.003124                  0.0  0.000000    0.0   \n",
       "...        ...     ...       ...                  ...       ...    ...   \n",
       "76045      0.0     0.0  0.005310                  0.0  0.000000    0.0   \n",
       "76046      0.0     0.0  0.003957                  0.0  0.000104    0.0   \n",
       "76047      0.0     0.0  0.003124                  0.0  0.000000    0.0   \n",
       "76048      0.0     0.0  0.002395                  0.0  0.000000    0.0   \n",
       "76049      0.0     0.0  0.002499                  0.0  0.000000    0.0   \n",
       "\n",
       "         TOTALP  HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0      0.000312     0.0             0.000104  0.003332                  0.0   \n",
       "1      0.000208     0.0             0.000104  0.002082                  0.0   \n",
       "2      0.000104     0.0             0.000104  0.002187                  0.0   \n",
       "3      0.000104     0.0             0.000104  0.001978                  0.0   \n",
       "4      0.000312     0.0             0.000104  0.003124                  0.0   \n",
       "...         ...     ...                  ...       ...                  ...   \n",
       "76045  0.000104     0.0             0.000104  0.001874                  0.0   \n",
       "76046  0.000521     0.0             0.000104  0.002811                  0.0   \n",
       "76047  0.000208     0.0             0.000104  0.003228                  0.0   \n",
       "76048  0.000208     0.0             0.000104  0.003853                  0.0   \n",
       "76049  0.000208     0.0             0.000104  0.003228                  0.0   \n",
       "\n",
       "       HERPES     FEDUC  ACLUNG   RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0         0.0  0.001249     0.0  0.000104  0.000104                  0.0   \n",
       "1         0.0  0.001249     0.0  0.000208  0.000208                  0.0   \n",
       "2         0.0  0.001249     0.0  0.000104  0.000104                  0.0   \n",
       "3         0.0  0.001249     0.0  0.000104  0.000104                  0.0   \n",
       "4         0.0  0.001666     0.0  0.000104  0.000104                  0.0   \n",
       "...       ...       ...     ...       ...       ...                  ...   \n",
       "76045     0.0  0.001249     0.0  0.000104  0.000104                  0.0   \n",
       "76046     0.0  0.000937     0.0  0.000104  0.000104                  0.0   \n",
       "76047     0.0  0.001458     0.0  0.000104  0.000104                  0.0   \n",
       "76048     0.0  0.001249     0.0  0.000104  0.000104                  0.0   \n",
       "76049     0.0  0.001770     0.0  0.000104  0.000104                  0.0   \n",
       "\n",
       "         VISITS   PINFANT  UTERINE  \n",
       "0      0.001666  0.000104      0.0  \n",
       "1      0.001354  0.000000      0.0  \n",
       "2      0.001145  0.000000      0.0  \n",
       "3      0.001041  0.000000      0.0  \n",
       "4      0.001354  0.000000      0.0  \n",
       "...         ...       ...      ...  \n",
       "76045  0.001874  0.000000      0.0  \n",
       "76046  0.000416  0.000000      0.0  \n",
       "76047  0.001041  0.000000      0.0  \n",
       "76048  0.001354  0.000000      0.0  \n",
       "76049  0.001041  0.000000      0.0  \n",
       "\n",
       "[76050 rows x 20 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing it myself since theres no columns with just words on it \n",
    "#thank you https://stackoverflow.com/questions/66809458/minmaxscaler-with-range-from-multiple-columns-in-dataframe\n",
    "\n",
    "# TESTING SCALE - using built in libraries \n",
    "\n",
    "\n",
    "\n",
    "xtestScale = X_test_t20.copy()\n",
    "print(type(xtestScale))\n",
    "# xtestList = xtestScale[\"Corr Score\"].values.astype(float).reshape(-1,1)\n",
    "\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# X_test_scale_mm = scaler.fit_transform(xtestList)\n",
    "# print(type(X_test_scale_mm))\n",
    "\n",
    "\n",
    "# xtestScale[\"Corr Score\"] = X_test_scale_mm \n",
    "# X_test_scale_mm = xtestScale \n",
    "\n",
    "# X_test_scale_mm.rename(columns = {X_test_scale_mm.columns[1]:\"Scaled Value\"}, inplace = True)\n",
    "# X_test_scale_mm\n",
    "\n",
    "minusTEST = xtestScale.min().min()    # df['Low'].min()\n",
    "maxasTEST = xtestScale.max().max()    # df['High'].max()\n",
    "X_test_scaled_mm = (X_test_scaled_mm - minus) / (maxas - minus)\n",
    "X_test_scaled_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 9: \n",
    "* Apply standardization (i.e., normalization) scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_std.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_std.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>1.453164</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>0.422203</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>0.715153</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>0.951579</td>\n",
       "      <td>13.034441</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>1.453164</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>-1.297704</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>0.446718</td>\n",
       "      <td>0.426965</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>0.148919</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>0.570365</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.921589</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>-1.129966</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.386188</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.753834</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.921589</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>-1.465442</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.653742</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>0.422203</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>0.379677</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>1.051499</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>0.148919</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76045</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>1.526730</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.921589</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>-1.633180</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>1.486687</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76046</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>0.570365</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>0.790794</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>1.765995</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>-0.123537</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-1.341376</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-2.259063</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76047</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>0.367820</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.653742</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76048</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.533134</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>1.553844</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>-0.315858</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>0.148919</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76049</th>\n",
       "      <td>-0.065207</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.459567</td>\n",
       "      <td>-0.197497</td>\n",
       "      <td>-0.462407</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.123088</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.114019</td>\n",
       "      <td>1.393339</td>\n",
       "      <td>-0.106126</td>\n",
       "      <td>-0.352701</td>\n",
       "      <td>-0.338691</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-0.653742</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.05823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CARDIAC    CERVIX    GAINED  onehotencoder__x1_S     TERMS     BDEAD  \\\n",
       "0     -0.065207 -0.061976  1.453164            -0.197497 -0.462407 -0.106858   \n",
       "1     -0.065207 -0.061976  1.453164            -0.197497 -0.462407 -0.106858   \n",
       "2     -0.065207 -0.061976  0.570365            -0.197497 -0.462407 -0.106858   \n",
       "3     -0.065207 -0.061976 -0.753834            -0.197497 -0.462407 -0.106858   \n",
       "4     -0.065207 -0.061976 -0.018168            -0.197497 -0.462407 -0.106858   \n",
       "...         ...       ...       ...                  ...       ...       ...   \n",
       "76045 -0.065207 -0.061976  1.526730            -0.197497 -0.462407 -0.106858   \n",
       "76046 -0.065207 -0.061976  0.570365            -0.197497  0.790794 -0.106858   \n",
       "76047 -0.065207 -0.061976 -0.018168            -0.197497 -0.462407 -0.106858   \n",
       "76048 -0.065207 -0.061976 -0.533134            -0.197497 -0.462407 -0.106858   \n",
       "76049 -0.065207 -0.061976 -0.459567            -0.197497 -0.462407 -0.106858   \n",
       "\n",
       "         TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0      0.422203 -0.123088             0.450213  0.715153            -0.032042   \n",
       "1     -0.249693 -0.123088             0.450213 -1.297704            -0.032042   \n",
       "2     -0.921589 -0.123088             0.450213 -1.129966            -0.032042   \n",
       "3     -0.921589 -0.123088             0.450213 -1.465442            -0.032042   \n",
       "4      0.422203 -0.123088             0.450213  0.379677            -0.032042   \n",
       "...         ...       ...                  ...       ...                  ...   \n",
       "76045 -0.921589 -0.123088             0.450213 -1.633180            -0.032042   \n",
       "76046  1.765995 -0.123088             0.450213 -0.123537            -0.032042   \n",
       "76047 -0.249693 -0.123088             0.450213  0.547415            -0.032042   \n",
       "76048 -0.249693 -0.123088             0.450213  1.553844            -0.032042   \n",
       "76049 -0.249693 -0.123088             0.450213  0.547415            -0.032042   \n",
       "\n",
       "         HERPES     FEDUC    ACLUNG   RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0     -0.114019 -0.315858 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "1     -0.114019 -0.315858 -0.106126  0.446718  0.426965            -0.036826   \n",
       "2     -0.114019 -0.315858 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "3     -0.114019 -0.315858 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "4     -0.114019  1.051499 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "...         ...       ...       ...       ...       ...                  ...   \n",
       "76045 -0.114019 -0.315858 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "76046 -0.114019 -1.341376 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "76047 -0.114019  0.367820 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "76048 -0.114019 -0.315858 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "76049 -0.114019  1.393339 -0.106126 -0.352701 -0.338691            -0.036826   \n",
       "\n",
       "         VISITS    PINFANT  UTERINE  \n",
       "0      0.951579  13.034441 -0.05823  \n",
       "1      0.148919  -0.076719 -0.05823  \n",
       "2     -0.386188  -0.076719 -0.05823  \n",
       "3     -0.653742  -0.076719 -0.05823  \n",
       "4      0.148919  -0.076719 -0.05823  \n",
       "...         ...        ...      ...  \n",
       "76045  1.486687  -0.076719 -0.05823  \n",
       "76046 -2.259063  -0.076719 -0.05823  \n",
       "76047 -0.653742  -0.076719 -0.05823  \n",
       "76048  0.148919  -0.076719 -0.05823  \n",
       "76049 -0.653742  -0.076719 -0.05823  \n",
       "\n",
       "[76050 rows x 20 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_std = xTrainTop20.copy()\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "# STDscale = StandardScaler().fit_transform(X_train_scaled_std[['Corr Score']])\n",
    "# print(STDscale)\n",
    "\n",
    "# X_train_scaled_std[\"Corr Score\"] = STDscale \n",
    "\n",
    "# X_train_scaled_std.rename(columns = {X_train_scaled_std.columns[1]:\"Scaled STD Value\"}, inplace = True)\n",
    "\n",
    "X_train_scaled_std =(X_train_scaled_std-X_train_scaled_std.mean())/X_train_scaled_std.std()\n",
    "X_train_scaled_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>FEDUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>0.967502</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>1.268836</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>0.190672</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>1.045799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-0.652903</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.589526</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>8.500767</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>-0.964881</td>\n",
       "      <td>-0.759502</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>-0.319270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-0.112768</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.249871</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>-1.133102</td>\n",
       "      <td>0.263762</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.295180</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>-1.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>0.697435</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>-0.089784</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>-1.051864</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>-0.319270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-1.463105</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.929181</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>5.263825</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>0.380890</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>1.045799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-1.193038</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.249871</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>-0.123774</td>\n",
       "      <td>-2.221309</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.505334</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>0.021997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-0.112768</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>-2.467369</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>-1.684338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-2.543375</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>-1.108749</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>1.053776</td>\n",
       "      <td>-0.174780</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>0.905591</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>-1.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-0.652903</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>1.268836</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>1.894883</td>\n",
       "      <td>-0.101689</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-1.095694</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>1.387066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>-0.059689</td>\n",
       "      <td>-0.030134</td>\n",
       "      <td>-0.112768</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>1.268836</td>\n",
       "      <td>-0.106895</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.196774</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>-0.040248</td>\n",
       "      <td>-0.189968</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>1.558440</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.295180</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>1.045799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RHSEN  onehotencoder__x1_U    VISITS  onehotencoder__x0_O     MEDUC  \\\n",
       "0     -0.059689            -0.030134  0.967502            -0.035551  1.268836   \n",
       "1     -0.059689            -0.030134 -0.652903            -0.035551  0.589526   \n",
       "2     -0.059689            -0.030134 -0.112768            -0.035551  0.249871   \n",
       "3     -0.059689            -0.030134  0.697435            -0.035551 -0.089784   \n",
       "4     -0.059689            -0.030134 -1.463105            -0.035551  0.929181   \n",
       "...         ...                  ...       ...                  ...       ...   \n",
       "25345 -0.059689            -0.030134 -1.193038            -0.035551  0.249871   \n",
       "25346 -0.059689            -0.030134 -0.112768            -0.035551 -2.467369   \n",
       "25347 -0.059689            -0.030134 -2.543375            -0.035551 -1.108749   \n",
       "25348 -0.059689            -0.030134 -0.652903            -0.035551  1.268836   \n",
       "25349 -0.059689            -0.030134 -0.112768            -0.035551  1.268836   \n",
       "\n",
       "          BDEAD   HYPERCH  onehotencoder__x0_S    HYDRAM  onehotencoder__x1_O  \\\n",
       "0     -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "1     -0.106895  8.500767            -0.196774 -0.120696            -0.039753   \n",
       "2     -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "3     -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "4     -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "...         ...       ...                  ...       ...                  ...   \n",
       "25345 -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "25346 -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "25347 -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "25348 -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "25349 -0.106895 -0.117632            -0.196774 -0.120696            -0.039753   \n",
       "\n",
       "       HEMOGLOB    ANEMIA  onehotencoder__x1_C    HERPES      MAGE    GAINED  \\\n",
       "0     -0.040248 -0.189968            -0.036103 -0.113958  0.212669  0.190672   \n",
       "1     -0.040248 -0.189968            -0.036103 -0.113958 -0.964881 -0.759502   \n",
       "2     -0.040248 -0.189968            -0.036103 -0.113958 -1.133102  0.263762   \n",
       "3     -0.040248 -0.189968            -0.036103 -0.113958  0.044448 -1.051864   \n",
       "4     -0.040248  5.263825            -0.036103 -0.113958  0.380890 -0.028599   \n",
       "...         ...       ...                  ...       ...       ...       ...   \n",
       "25345 -0.040248 -0.189968            -0.036103 -0.113958 -0.123774 -2.221309   \n",
       "25346 -0.040248 -0.189968            -0.036103 -0.113958  0.212669 -0.028599   \n",
       "25347 -0.040248 -0.189968            -0.036103 -0.113958  1.053776 -0.174780   \n",
       "25348 -0.040248 -0.189968            -0.036103 -0.113958  1.894883 -0.101689   \n",
       "25349 -0.040248 -0.189968            -0.036103 -0.113958  1.558440 -0.028599   \n",
       "\n",
       "        PRETERM     WEEKS  onehotencoder__x0_U     FEDUC  \n",
       "0     -0.094842  0.105077            -0.027387  1.045799  \n",
       "1     -0.094842  0.105077            -0.027387 -0.319270  \n",
       "2     -0.094842 -0.295180            -0.027387 -1.001804  \n",
       "3     -0.094842  0.105077            -0.027387 -0.319270  \n",
       "4     -0.094842  0.105077            -0.027387  1.045799  \n",
       "...         ...       ...                  ...       ...  \n",
       "25345 -0.094842  0.505334            -0.027387  0.021997  \n",
       "25346 -0.094842  0.105077            -0.027387 -1.684338  \n",
       "25347 -0.094842  0.905591            -0.027387 -1.001804  \n",
       "25348 -0.094842 -1.095694            -0.027387  1.387066  \n",
       "25349 -0.094842 -0.295180            -0.027387  1.045799  \n",
       "\n",
       "[25350 rows x 20 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_std = X_test_t20.copy()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# STDscaleOHE = StandardScaler().fit_transform(X_test_scaled_std[['Corr Score']])\n",
    "\n",
    "# print(STDscaleOHE)\n",
    "# X_test_scaled_std[\"Corr Score\"] = STDscaleOHE \n",
    "\n",
    "# X_test_scaled_std.rename(columns = {X_test_scaled_std.columns[1]:\"Scaled STD Value\"}, inplace = True)\n",
    "\n",
    "X_test_scaled_std =(X_test_scaled_std-X_test_scaled_std.mean())/X_test_scaled_std.std()\n",
    "X_test_scaled_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 10: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_closed_form_training** : It fits a linear regression model using the closed-form solution to obtain the coefficients, beta's, as a numpy array of m+1 values (Please recall class lecture), where *m* is the number of variables kept in X_train (the first argument to the function). Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://urldefense.com/v3/__https://docs.python.org/3/library/time.html__;!!CXsS5Xclluo!34J7Vol-cvnN-I7o-iHw5CdltH-laBqpLbJDISG_-4diCU0yfgjcAxgAOZhaIjlDtbs$  . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_closed_form_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function.\n",
    "* **RMSE**: It takes two lists: y_test, y_pred, where the first list represents ground truth (i.e., actual) target values for the given samples, and the second list represents a corresponding predicted values for exactly same number of samples in y_test. Compute and return the Root Mean Squared Error (RMSE) of the prediction. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_closed_form_training() function providing X_train_scaled_std, y_train obtained from Task 9, and save the returned results as betas_closed_form,cpu_time_closed_form.\n",
    "* Print betas_closed_form, cpu_time_closed_form\n",
    "* Call linear_regression_closed_form_predict() function providing betas_closed_form,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_closed_form.\n",
    "* Print rmse_closed_form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDscale\n",
    "# m = STDscale.shape[0]\n",
    "# train1 = np.c_[np.ones((m)), STDscale]\n",
    "# df = pd.DataFrame(train1 , columns = ['bias' , 'std scale'])\n",
    "\n",
    "# # X_transpose = train1.T\n",
    "    \n",
    "\n",
    "# # bet = inv(X_transpose.dot(train1 )).dot(X_transpose).dot(y_train)  \n",
    "    \n",
    "# closedForm = np.linalg.inv(df.T.dot(df)).dot(df.T).dot(y_train) # normal equation\n",
    "#     #closedForm = np.dot(np.dot(inv(np.dot(X_train.T, X_train)), X_train.T) , y_train)\n",
    "# print(closedForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 1 column as bias \n",
    "X_test_scaled_std.insert(loc = 0, column =\"Bias\", value = 1)\n",
    "X_train_scaled_std.insert(loc = 0, column =\"Bias\", value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled_std, y_train\n",
    "# = STDscale , y train - if i just want the data without it being in a df \n",
    "\n",
    "#https://towardsdatascience.com/performing-linear-regression-using-the-normal-equation-6372ed3c57\n",
    "#closedForm = np.linalg.inv(STDscale.T.dot(STDscale)).dot(STDscale.T).dot(y_train) # normal equation\n",
    "\n",
    "\n",
    "def linear_regression_closed_form_training(X_train, y_train):\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    from time import perf_counter\n",
    "    cpu_time = 0\n",
    "    betas = []\n",
    "    startClosedTime = perf_counter()\n",
    "    \n",
    "\n",
    "    #@TODO: Your code goes here\n",
    "    \n",
    "    \n",
    "    #m = X_train.shape[0]\n",
    "    #y = y_train.values.reshape(m,1)\n",
    "    \n",
    "    #train1 = np.c_[np.ones((m)), X_train] # set bias term to 1 for each sample and adding it to xtrain\n",
    "    \n",
    "    #https://www.c-sharpcorner.com/article/normal-equation-implementation-from-scratch-in-python/\n",
    "    \n",
    "    #X_train['bias'] = 1\n",
    "    X_train_transpose = X_train.T \n",
    "    beta = np.dot(np.linalg.inv(np.dot(X_train_transpose, X_train)), np.dot(X_train_transpose, y_train))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #X_transpose = X_train.T\n",
    "#     x_new = x_new=np.array([np.ones(len(X_train))]).T\n",
    "#     fx_new = x_new=np.array([np.ones(len(X_train))]).T\n",
    "#     closedForm = np.linalg.inv(x_new.T.dot(x_new)).dot(x_new.T).dot(y_train)\n",
    "    #bet = inv(X_transpose.dot(train1 )).dot(X_transpose).dot(y_train)  \n",
    "    #closedForm = np.linalg.inv(X_transpose.dot(X_train)).dot(X_transpose).dot(y_train) # normal equation\n",
    "    #closedForm = np.linalg.inv(X_transpose.T.dot(X_train)).dot(X_transpose.T).dot(y_train)# normal equation\n",
    "    \n",
    "    \n",
    "    #closedForm = np.dot(np.dot(inv(np.dot(X_train.T, X_train)), X_train.T) , y_train)\n",
    "    betas.append(beta)\n",
    "\n",
    "    endClosedTime = perf_counter()\n",
    "    cpu_time = endClosedTime - startClosedTime\n",
    "    \n",
    "    return betas,cpu_time\n",
    "\n",
    "def linear_regression_closed_form_predict(betas, X_test):\n",
    "    y_pred = []\n",
    "    #https://towardsdatascience.com/normal-equation-in-python-the-closed-form-solution-for-linear-regression-13df33f9ad71\n",
    "    #@TODO: Your code goes here\n",
    "\n",
    "    #X_test = 1\n",
    "    # Appending a cloumn of ones in X to add the bias term.\n",
    "    \n",
    "    \n",
    "    # preds is y_hat which is the dot product of X and theta.\n",
    "    #print(\"shape\", X_test.shape())\n",
    "    y_pred = (np.dot(X_test, betas))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def RMSE(y_test, y_pred):\n",
    "    rmse = -1\n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "    #https://www.askpython.com/python/examples/rmse-root-mean-square-error\n",
    "    import math\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    #https://www.geeksforgeeks.o    X_test = 1rg/python-mean-squared-error/\n",
    "    \n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    mse = np.square(np.subtract(y_test,y_pred)).mean() \n",
    "    rmse  = math.sqrt(mse)\n",
    "\n",
    "    \n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Closed time = 0.017185499999868625\n",
      "Beta Values:\n",
      "            0\n",
      "0   7.256998\n",
      "1  -0.002839\n",
      "2  -0.084814\n",
      "3   0.229267\n",
      "4  -0.015424\n",
      "5  -0.099020\n",
      "6  -0.048934\n",
      "7   0.091285\n",
      "8  -0.064073\n",
      "9  -0.083756\n",
      "10  0.062535\n",
      "11 -0.009343\n",
      "12  0.001467\n",
      "13  0.048084\n",
      "14 -0.001238\n",
      "15 -0.064952\n",
      "16 -0.039279\n",
      "17 -0.001862\n",
      "18  0.151929\n",
      "19  0.078232\n",
      "20 -0.048115\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Now, call linear_regression_closed_form_training() function providing X_train_scaled_std, y_train obtained from Task 9, \n",
    "#and save the returned results as betas_closed_form,cpu_time_closed_form.\n",
    "\n",
    "m = X_train_scaled_std.shape[0]\n",
    "xc = np.c_[np.ones((m)), X_train_scaled_std]\n",
    "\n",
    "betaCPU = linear_regression_closed_form_training(X_train_scaled_std, y_train) #returns betas and cpu time as tuple and assign\n",
    "\n",
    "betas_closed_form = betaCPU[0]\n",
    "cpu_time_closed_form = betaCPU[1]\n",
    "\n",
    "\n",
    "\n",
    "betas_closed_form = [item for sublist in betas_closed_form for item in sublist]\n",
    "\n",
    "betas_closed_form = [item for sublist in betas_closed_form for item in sublist]\n",
    "\n",
    "betas_closed_form = pd.DataFrame(betas_closed_form)\n",
    "\n",
    "print(\"Linear Regression Closed time =\", cpu_time_closed_form)\n",
    "print(\"Beta Values:\\n\", betas_closed_form )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.312051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.974025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.287528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.510077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.794113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>7.144272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>7.574315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>6.922416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>6.643913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>6.924772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      7.312051\n",
       "1      7.974025\n",
       "2      7.287528\n",
       "3      7.510077\n",
       "4      6.794113\n",
       "...         ...\n",
       "25345  7.144272\n",
       "25346  7.574315\n",
       "25347  6.922416\n",
       "25348  6.643913\n",
       "25349  6.924772\n",
       "\n",
       "[25350 rows x 1 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#Call linear_regression_closed_form_predict() function providing betas_closed_form,X_test_scaled_std obtained in Task 9. \n",
    "#Save the returned result as y_pred.\n",
    "print(type(X_test_scaled_std.shape))\n",
    "y_pred = linear_regression_closed_form_predict(betas_closed_form,X_test_scaled_std)\n",
    "\n",
    "y_pred = [item for sublist in y_pred for item in sublist]\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2773539479615261"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Call RMSE() function providing y_test and y_pred. \n",
    "#Save returned result as rmse_closed_form.\n",
    "\n",
    "# print(y_test.shape)\n",
    "# print(y_pred.shape)\n",
    "\n",
    "\n",
    "rmse_closed_form = RMSE(y_test, y_pred)\n",
    "rmse_closed_form\n",
    "\n",
    "#operands could not be broadcast together with shapes (76050,1) (25350,1) \n",
    "# #from sklearn.metrics import mean_squared_error -ONLY TO SEE WHAT I SHOULD BE GETTING \n",
    "# MSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# MSE = 10.384876459346348\n",
    "#^ should be the number I should be getting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 11: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_batch_training** : It fits a linear regression model using the batch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate) and nEpoch (number of epochs) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://urldefense.com/v3/__https://docs.python.org/3/library/time.html__;!!CXsS5Xclluo!34J7Vol-cvnN-I7o-iHw5CdltH-laBqpLbJDISG_-4diCU0yfgjcAxgAOZhaIjlDtbs$  . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_batch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_batch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=1000, and save the returned results as betas_batch,cpu_time_batch.\n",
    "* Print betas_batch, cpu_time_batch\n",
    "* Call linear_regression_gd_batch_predict() function providing betas_batch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_batch.\n",
    "* Print rmse_batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_batch_training(X_train,y_train, alpha, nEpoch):\n",
    "    import random\n",
    "    random.seed(554433)\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    start = perf_counter()\n",
    "    #@TODO: Your code goes here   \n",
    "    #https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n",
    "    \n",
    "    #m = len(X_train)\n",
    "    y_hat = 0 \n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "    #y = y_train.values.reshape(m,1)    \n",
    "    #X_train = np.c_[np.ones((m)), X_train] # set bias term to 1 for each sample and adding it to xtrain\n",
    "      \n",
    "    #starting beta\n",
    "    for item in X_train:\n",
    "        \n",
    "        beta = random.random()\n",
    "        betas.append(beta)\n",
    "        \n",
    "    for i in range(nEpoch):\n",
    "        copyDF = X_train.copy()\n",
    "        \n",
    "        for que in range(0,len(X_train.columns)):\n",
    "            whatDF = X_train[X_train.columns[que]]* betas[que]\n",
    "            copyDF[copyDF.columns[que]] = whatDF\n",
    "            \n",
    "        copyDF[\"BWEIGHT\"] = copyDF.sum(axis=1)\n",
    "        yHat = copyDF[\"BWEIGHT\"]\n",
    "        yHat = pd.DataFrame(yHat)\n",
    "             \n",
    "        index = 0\n",
    "        for col in X_train.columns:\n",
    "            beta = betas[index]\n",
    "            \n",
    "            #beta0\n",
    "            if index ==0:\n",
    "                beta = beta- alpha * (1/m) * (np.sum(y_train.sub(yHat)))   \n",
    "                beta[index] = beta\n",
    "                index += 1 \n",
    "            \n",
    "            #beta rest\n",
    "            else:\n",
    "                beta  = beta  - alpha * (1/m) * np.dot(np.transpose(X_train[col]), y_hat-y_train)\n",
    "            \n",
    "                betas[index] = beta\n",
    "                index +=1 \n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "    end = perf_counter()\n",
    "    cpu_time = end - start\n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_batch_predict(betas,X_test):\n",
    "    y_pred = []\n",
    "    #@TODO: Your code goes here\n",
    "    # Appending a cloumn of ones in X to add the bias term.\n",
    "    #X_test = np.append(X_test, np.ones((X_test.shape[0],1)), axis=1)\n",
    "\n",
    "    # preds is y_hat which is the dot product of X and theta.\n",
    "    #y_pred.append(np.dot(X_test, betas))\n",
    "    y_pred = (np.dot(X_test, betas))\n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 error = y_train.sub(yHat)\n",
    "#                 diff = X_train_scaled_std[col].T.dot(error)\n",
    "#                 totDif = (1/m) * (np.sum(diff))\n",
    "#                 beta = beta- alpha*totDiff\n",
    "\n",
    "#         y_hat = np.dot(X_train, beta)\n",
    "#         beta = beta - alpha * (1.0/m) * np.dot(X_train.T, y_hat-y_train)\n",
    "#         #or also y_hat\n",
    "# #         hypothesis = np.dot(X_train, beta)\n",
    "# #         print(hypothesis)\n",
    "# #         loss = hypothesis - y_train\n",
    "# #         xTranspose = X_train.transpose()\n",
    "# #         gradient = np.dot(xTranspose,loss)/ m\n",
    "# #         betaNew = beta - alpha * gradient\n",
    "\n",
    "# #         hypothesis = beta * X_train + yint  # The current predicted value of Y\n",
    "# #         D_m = (-2/m) * np.sum(X_train * (y_train - hypothesis))  # Derivative wrt m\n",
    "# #         D_c = (-2/m) * np.sum(y_train - hypothesis)  # Derivative wrt c\n",
    "# #         beta = beta - alpha * D_m  # Update m\n",
    "# #         yint = yint - alpha * D_c  # Update c\n",
    "#         #\n",
    "#         #beta  = beta  - alpha * (1/m) * np.dot(np.transpose(X_train), y_hat-y_train)\n",
    "#         betas.append(betaNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Batch time = 100.88982149999993\n",
      "Beta Values:\n",
      "                          0\n",
      "0                0.0952941\n",
      "1     [0.6814966110762509]\n",
      "2   [-0.47200703155047097]\n",
      "3      [2.557878605049859]\n",
      "4    [0.17362650839976368]\n",
      "5    [0.47750355437921765]\n",
      "6   [-0.35523929928828574]\n",
      "7     [0.7054873178669392]\n",
      "8    [-0.3604007840733686]\n",
      "9   [-0.12916482326149803]\n",
      "10     [1.648120021913885]\n",
      "11    [0.1824045538180552]\n",
      "12     [0.819122806571292]\n",
      "13     [1.564126679180041]\n",
      "14    [0.6401766933544865]\n",
      "15  [-0.18151379419776162]\n",
      "16   [-0.8839947740486912]\n",
      "17  [0.007915300403343872]\n",
      "18    [2.3768389932148453]\n",
      "19    [1.8332367472705853]\n",
      "20   [0.07458284969275683]\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: \n",
    "#complete the three function definitions and demonstrate the functionalities of each by calling them with \n",
    "#appropriate arguments as instructed below:\n",
    "#Now, call linear_regression_gd_batch_training() function providing X_train_scaled_std, y_train obtained from Task 9, \n",
    "#and alpha=0.01,nEpoch=1000, and save the returned results as betas_batch,cpu_time_batch.\n",
    "\n",
    "#Print betas_batch, cpu_time_batch\n",
    "alpha=0.01\n",
    "nEpoch=1000\n",
    "\n",
    "batch = linear_regression_gd_batch_training(X_train_scaled_std, y_train, alpha, nEpoch)\n",
    "\n",
    "betas_batch = batch[0]\n",
    "cpu_time_batch = batch[1]\n",
    "\n",
    "\n",
    "\n",
    "# betas_batch = [item for sublist in betas_batch for item in sublist]\n",
    "\n",
    "# betas_batch = [item for sublist in betas_batch for item in sublist]\n",
    "\n",
    "betas_batch = pd.DataFrame(betas_batch)\n",
    "\n",
    "print(\"Linear Regression Batch time =\", cpu_time_batch)\n",
    "print(\"Beta Values:\\n\", betas_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.896534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.459413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.277623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.584107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.147776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>-0.048188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>-1.660504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>-5.298808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>-4.123750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>-0.868453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      2.896534\n",
       "1      5.459413\n",
       "2     -1.277623\n",
       "3      2.584107\n",
       "4      1.147776\n",
       "...         ...\n",
       "25345 -0.048188\n",
       "25346 -1.660504\n",
       "25347 -5.298808\n",
       "25348 -4.123750\n",
       "25349 -0.868453\n",
       "\n",
       "[25350 rows x 1 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Call linear_regression_gd_batch_predict() function providing betas_batch,X_test_scaled_std obtained in Task 9. \n",
    "#Save the returned result as y_pred.\n",
    "\n",
    "\n",
    "y_predBatch = linear_regression_gd_batch_predict(betas_batch,X_test_scaled_std)\n",
    "\n",
    "y_predBatch  = [item for sublist in y_predBatch  for item in sublist]\n",
    "y_predBatch  = [item for sublist in y_predBatch  for item in sublist]\n",
    "\n",
    "y_predBatch  = pd.DataFrame(y_predBatch)\n",
    "\n",
    "y_predBatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.626966530202031"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Call RMSE() function providing y_test and y_pred. Save returned result as rmse_batch.\n",
    "\n",
    "#Print rmse_batch\n",
    "rmse_batch = RMSE(y_test, y_predBatch)\n",
    "rmse_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 12:\n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_stochastic_training** : It fits a linear regression model using the stochastic gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://urldefense.com/v3/__https://docs.python.org/3/library/time.html__;!!CXsS5Xclluo!34J7Vol-cvnN-I7o-iHw5CdltH-laBqpLbJDISG_-4diCU0yfgjcAxgAOZhaIjlDtbs$  . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_stochastic_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_stochastic_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=50, nIteration=100 , and save the returned results as betas_stochastic,cpu_time_stochastic.\n",
    "* Print betas_stochastic, cpu_time_stochastic\n",
    "* Call linear_regression_gd_stochastic_predict() function providing betas_stochastic,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_stochastic.\n",
    "* Print rmse_stochastic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_stochastic_training(X_train,y_train,alpha,nEpoch,nIteration):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "\n",
    "    ## YOUR CODE HERE ###\n",
    "    m = len(X_train)\n",
    "    start = perf_counter()\n",
    "\n",
    "    #setting variables for \n",
    "    #y = mx + b \n",
    "    #setting 20 since we need 20 variables \n",
    "    #https://towardsdatascience.com/implementing-sgd-from-scratch-d425db18a72c\n",
    "    \n",
    "\n",
    "    beta = np.c_[np.ones((m)), X_train]\n",
    "    \n",
    "    beta = np.random.randn(1,21)  \n",
    "    yint = np.random.randn(1,1)   # Random intercept value\n",
    "    \n",
    "    count=1\n",
    "    while count <= nEpoch:\n",
    "        \n",
    "        temp = X_train.sample(nIteration)\n",
    "\n",
    "        xtemp = temp.iloc[:,0:21].values\n",
    "        ytemp = temp.iloc[:,-1].values\n",
    "\n",
    "        \n",
    "        for i in range(nIteration):\n",
    "\n",
    "            #beta = beta -(1/m)*alpha*(X_train.T.dot((prediction - y_train)))\n",
    "            beta = beta - alpha* (-2/nIteration * xtemp[i]) * (ytemp [i] - np.dot(xtemp[i],beta.T) - yint)\n",
    "            yint = yint - alpha * (-2/nIteration) * (ytemp [i] - np.dot(xtemp[i],beta.T) - yint)\n",
    "            \n",
    "            yhat = np.dot(xtemp[i],beta.T)\n",
    "            betas.append(yhat)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #loss = RMSE(y_pred, y_tr)     \n",
    "        #print(\"Epoch:\", count, \"Loss:\", loss)\n",
    "        count +=1\n",
    "    \n",
    "        \n",
    "########################## SKIP DOESNT WORK BUT DOESNT KNOW WHY#####################################\n",
    "#     for item in X_train:\n",
    "        \n",
    "#         beta = random.random()\n",
    "#         betas.append(beta)\n",
    "      \n",
    "#    #basically the same as batch descent  \n",
    "#     for i in range(nEpoch):\n",
    "#         copyDF = X_train.copy()\n",
    "        \n",
    "#         for que in range(0,len(X_train.columns)):\n",
    "#             whatDF = X_train[X_train.columns[que]]* betas[que]\n",
    "#             copyDF[copyDF.columns[que]] = whatDF\n",
    "            \n",
    "#         copyDF[\"BWEIGHT\"] = copyDF.sum(axis=1)\n",
    "#         yHat = copyDF[\"BWEIGHT\"]\n",
    "#         yHat = pd.DataFrame(yHat)\n",
    "     \n",
    "        \n",
    "#     for it in range(nIteration):\n",
    "\n",
    "#         for i in range(m):\n",
    "#             rand_ind = np.random.randint(0,m)\n",
    "#             X_train = X_train[rand_ind,:].reshape(1,X.shape[1])\n",
    "#             y_train = y_train[rand_ind].reshape(1,1)\n",
    "#             prediction = np.dot(X_train,beta)\n",
    "\n",
    "#             beta = beta -(1/m)*alpha*(X_train.T.dot((prediction - y_train)))        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         for col in X_train.columns:\n",
    "#             randRow = X_train.sample(1)\n",
    "#             for row in randRow:\n",
    "#                 randIndex = row\n",
    "            \n",
    "            \n",
    "#             y_train_rand = y_train.loc[[randIndex]]\n",
    "#             yHatRand = yHat.loc[[randIndex]]\n",
    "            \n",
    "#             #beta0\n",
    "#             if index ==0:\n",
    "#                 beta = beta- alpha * (1/m)* (np.sum((y_train_rand.sub(yHatRand))))\n",
    "#                 beta[index] = beta\n",
    "#                 index += 1 \n",
    "            \n",
    "#             #beta rest\n",
    "#             else:\n",
    "#                 beta = beta -(1/m)*alpha*(X_train.T.dot((prediction - y_train)))\n",
    "                \n",
    "                \n",
    "#                 betas[index] = beta\n",
    "#                 index +=1           \n",
    "##################################################################################################################        \n",
    "\n",
    "    \n",
    "    end = perf_counter()\n",
    "    cpu_time = end- start \n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_stochastic_predict(betas, X_test):\n",
    "\n",
    "    y_pred = []\n",
    "    ## YOUR CODE HERE ###\n",
    "    # Appending a cloumn of ones in X to add the bias term.\n",
    "    #betas.append(1)\n",
    "    # preds is y_hat which is the dot product of X and theta.\n",
    "    y_pred = np.dot(X_test, betas)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression stochastic time = 0.2054349000009097\n",
      "Beta Values:\n",
      "             0\n",
      "0    1.459581\n",
      "1    3.540663\n",
      "2    4.756314\n",
      "3    4.474922\n",
      "4    3.245148\n",
      "5   -0.127986\n",
      "6    4.319796\n",
      "7    8.793842\n",
      "8   33.114121\n",
      "9    8.577168\n",
      "10   3.661392\n",
      "11  -5.113556\n",
      "12   5.617597\n",
      "13   3.717301\n",
      "14   4.785978\n",
      "15   3.831901\n",
      "16   3.187995\n",
      "17   5.421605\n",
      "18  11.763191\n",
      "19   2.950056\n",
      "20   2.385141\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#Now, call linear_regression_gd_stochastic_training() function providing X_train_scaled_std, y_train obtained from Task 9, \n",
    "#and alpha=0.01,nEpoch=50, nIteration=100 , and save the returned results as betas_stochastic,cpu_time_stochastic.\n",
    "\n",
    "#Print betas_stochastic, cpu_time_stochastic\n",
    "\n",
    "\n",
    "alpha=0.01\n",
    "nEpoch=50\n",
    "nIteration=100\n",
    "\n",
    "betas_stochastic,cpu_time_stochastic = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "\n",
    "\n",
    "betas_stochastic  = [item for sublist in betas_stochastic for item in sublist]\n",
    "betas_stochastic = pd.DataFrame(betas_stochastic)[:21]\n",
    "\n",
    "print(\"Linear Regression stochastic time =\", cpu_time_stochastic)\n",
    "print(\"Beta Values:\\n\", betas_stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.019082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.808234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-20.238761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.915413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.730396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>-17.269124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>-12.585820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>-9.834929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>-16.067165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>-6.103679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      -1.019082\n",
       "1      56.808234\n",
       "2     -20.238761\n",
       "3      -9.915413\n",
       "4      18.730396\n",
       "...          ...\n",
       "25345 -17.269124\n",
       "25346 -12.585820\n",
       "25347  -9.834929\n",
       "25348 -16.067165\n",
       "25349  -6.103679\n",
       "\n",
       "[25350 rows x 1 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#Call linear_regression_gd_stochastic_predict() function providing betas_stochastic,X_test_scaled_std obtained in Task 9. \n",
    "#Save the returned result as y_pred.\n",
    "\n",
    "y_predSto = linear_regression_gd_stochastic_predict(betas_stochastic,X_test_scaled_std)\n",
    "\n",
    "y_predSto   = [item for sublist in y_predSto for item in sublist]\n",
    "y_predSto = pd.DataFrame(y_predSto )\n",
    "\n",
    "y_predSto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.48354977508695"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Call RMSE() function providing y_test and y_pred. Save returned result as rmse_stochastic.\n",
    "\n",
    "#Print rmse_stochastic.\n",
    "\n",
    "rmse_stochastic = RMSE(y_test,y_predSto)\n",
    "rmse_stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 13: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_minibatch_training** : It fits a linear regression model using the minibatch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations), and batch_size parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://urldefense.com/v3/__https://docs.python.org/3/library/time.html__;!!CXsS5Xclluo!34J7Vol-cvnN-I7o-iHw5CdltH-laBqpLbJDISG_-4diCU0yfgjcAxgAOZhaIjlDtbs$  . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_minibatch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_minibatch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.001,nEpoch=50, nIteration=1000,batch_size=32, and save the returned results as betas_minibatch,cpu_time_minibatch.\n",
    "* Print betas_minibatch, cpu_time_minibatch\n",
    "* Call linear_regression_gd_minibatch_predict() function providing betas_minibatch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_minibatch.\n",
    "* Print rmse_minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_minibatch_training(X_train,y_train,alpha,nEpoch, nIteration, batch_size):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    start = perf_counter()\n",
    "    ## YOUR CODE HERE ###\n",
    "#https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/   \n",
    "\n",
    "    batches = []\n",
    "    n = np.hstack((X_train, y_train))\n",
    "    np.random.shuffle(n)\n",
    "    n_minibatches = n[0] // batch_size\n",
    "    i = 0\n",
    "  \n",
    "\n",
    "    for i in range(nEpoch + 1):\n",
    "        mini_batch = n[i * batch_size:(i + 1)* batch_size, :]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        batches.append((X_mini, Y_mini))\n",
    "        \n",
    "    if n.shape[0] % batch_size != 0:\n",
    "        mini_batch = n[i * batch_size:n.shape[0]]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        batches.append((X_mini, Y_mini))\n",
    "        \n",
    "  \n",
    "#function to perform mini-batch gradient descent\n",
    "    beta = np.zeros((X_train.shape[1], 1))\n",
    "\n",
    "    for mini_batch in batches:\n",
    "            X_mini, y_mini = mini_batch\n",
    "            #beta  = beta  - alpha * (1/m) * np.dot(np.transpose(X_train[col]), y_hat-y_train)\n",
    "            beta = beta - alpha *np.dot(X_mini.transpose(), (np.dot(X_mini, beta) - y_mini))\n",
    "\n",
    "    betas.append(beta)\n",
    "   \n",
    "   \n",
    "    \n",
    "    \n",
    "    end = perf_counter()\n",
    "    cpu_time = end-start \n",
    "    return betas,cpu_time\n",
    "\n",
    "def linear_regression_gd_minibatch_predict(betas,X_test):\n",
    "    y_pred = []\n",
    "    ## YOUR CODE HERE ###\n",
    "\n",
    "    y_pred = np.dot(X_test, betas)\n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression miniBatch time = 0.14789169999858132\n",
      "Beta Values:\n",
      "              0\n",
      "0   108.784963\n",
      "1    -0.255164\n",
      "2    -6.679764\n",
      "3    -1.124798\n",
      "4     3.456365\n",
      "5    -0.020790\n",
      "6     7.867152\n",
      "7     4.557144\n",
      "8    -4.660399\n",
      "9    -1.053702\n",
      "10    2.505702\n",
      "11   -3.248373\n",
      "12    1.281352\n",
      "13   -3.835464\n",
      "14    2.280028\n",
      "15    5.450453\n",
      "16    6.525597\n",
      "17   -5.532862\n",
      "18   -5.106434\n",
      "19   -2.126056\n",
      "20    0.049446\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "#Now, call linear_regression_gd_minibatch_training() function providing X_train_scaled_std, y_train obtained from Task 9, \n",
    "#and alpha=0.001,nEpoch=50, nIteration=1000,batch_size=32, and \n",
    "#save the returned results as betas_minibatch,cpu_time_minibatch.\n",
    "\n",
    "alpha=0.001\n",
    "nEpoch=50 \n",
    "nIteration=1000\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "#Print betas_minibatch, cpu_time_minibatch\n",
    "betas_minibatch, cpu_time_minibatch = linear_regression_gd_minibatch_training(X_train_scaled_std, y_train,\n",
    "                                                                              alpha,nEpoch, nIteration, batch_size)\n",
    "betas_minibatch  = [item for sublist in betas_minibatch for item in sublist]\n",
    "betas_minibatch  = [item for sublist in betas_minibatch for item in sublist]\n",
    "betas_minibatch = pd.DataFrame(betas_minibatch )\n",
    "\n",
    "print(\"Linear Regression miniBatch time =\", cpu_time_minibatch)\n",
    "print(\"Beta Values:\\n\", betas_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.599047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138.024955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.919853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.838397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.814285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>92.382511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>109.325940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>111.608109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>124.831201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>118.762205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0      109.599047\n",
       "1      138.024955\n",
       "2      105.919853\n",
       "3      100.838397\n",
       "4      118.814285\n",
       "...           ...\n",
       "25345   92.382511\n",
       "25346  109.325940\n",
       "25347  111.608109\n",
       "25348  124.831201\n",
       "25349  118.762205\n",
       "\n",
       "[25350 rows x 1 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "#Call linear_regression_gd_minibatch_predict() function providing betas_minibatch,X_test_scaled_std obtained in Task 9. \n",
    "#Save the returned result as y_pred.\n",
    "\n",
    "y_predMini = linear_regression_gd_minibatch_predict(betas_minibatch,X_test_scaled_std)\n",
    "\n",
    "\n",
    "y_predMini   = [item for sublist in y_predMini for item in sublist]\n",
    "y_predMini = pd.DataFrame(y_predMini)\n",
    "y_predMini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.20966663291969"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "#Call RMSE() function providing y_test and y_pred. Save returned result as rmse_minibatch.\n",
    "\n",
    "#Print rmse_minibatch.\n",
    "\n",
    "rmseMini = RMSE(y_test,y_predMini)\n",
    "rmseMini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 14:\n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the best predictive performance in terms of RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed form: 1.2773539479615261 \n",
      "Batch: 8.626966530202031 \n",
      "Stochastic 40.48354977508695 \n",
      "MiniBatch 103.20966663291969\n",
      "\n",
      "Least RMSE is:\n",
      " 1.2773539479615261\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "# rmse_closed_form\n",
    "# rmse_batch\n",
    "# rmse_stochastic\n",
    "# rmseMini \n",
    "\n",
    "names = [\"rmse_closed_form\", \"rmse_batch\", \"rmse_stochastic\" , \"rmseMini\" ]\n",
    "\n",
    "print(\"Closed form:\", rmse_closed_form,\n",
    "     \"\\nBatch:\", rmse_batch,\n",
    "     \"\\nStochastic\", rmse_stochastic,\n",
    "     \"\\nMiniBatch\", rmseMini)\n",
    "rmse = []\n",
    "rmse.append(rmse_closed_form)\n",
    "rmse.append(rmse_batch)\n",
    "rmse.append(rmse_stochastic)\n",
    "rmse.append(rmseMini )\n",
    "\n",
    "rmseDF = pd.DataFrame()\n",
    "rmseDF[\"RMSE\"] = names\n",
    "rmseDF[\"Values\"] = rmse\n",
    "\n",
    "print(\"\\nLeast RMSE is:\\n\", min(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 15: \n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the least training cpu time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed form: 0.017185499999868625 \n",
      "Batch: 100.88982149999993 \n",
      "Stochastic 0.2054349000009097 \n",
      "MiniBatch 0.14789169999858132\n",
      "Least training time is: 0.017185499999868625\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "print(\"Closed form:\", cpu_time_closed_form,\n",
    "     \"\\nBatch:\", cpu_time_batch,\n",
    "     \"\\nStochastic\", cpu_time_stochastic,\n",
    "     \"\\nMiniBatch\", cpu_time_minibatch)\n",
    "cpu = []\n",
    "cpu.append(cpu_time_closed_form)\n",
    "cpu.append(cpu_time_batch)\n",
    "cpu.append(cpu_time_stochastic)\n",
    "cpu.append(cpu_time_minibatch)\n",
    "\n",
    "print(\"Least training time is:\", min(cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 16: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively, \n",
    "* call your implementation of Task 12: stochastic gradient descent based linear regression for each of these learning rates: {0.0001, 0.001, 0.05, 0.01, 0.1, 1.0}\n",
    "    * Please use the nIteration (number of iterations), nEpoch (number of epoch) parameters in your implementation of the gradient descent algorithm.\n",
    "\n",
    "* For each of the linear regression model, using the computed beta values, predict the test samples provided in the \"X_test_scaled_std\" argument, and let's name your prediction \"y_pred\".\n",
    "* Compute Root Mean Squared Error (RMSE) of your prediction using the RMSE() function you defined in Task 10.\n",
    "* Finally, print the learning rate that shows the best test performance, and also print as a pandas dataframe named summary with 2 columns: {learning_rate, test_RMSE} containing RMSE's of the 6 linear regression models. Also, print the best performing learning rate.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001 \n",
      "\n",
      "\n",
      "Alpha: 0.001 \n",
      "\n",
      "\n",
      "Alpha: 0.05 \n",
      "\n",
      "\n",
      "Alpha: 0.01 \n",
      "\n",
      "\n",
      "Alpha: 0.1 \n",
      "\n",
      "\n",
      "Alpha: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "#i know theres an easier way, idk how to go about it and I dont have the time rn \n",
    "learningRate = [0.0001, 0.001, 0.05, 0.01, 0.1, 1.0]\n",
    "alpha = 0.0001\n",
    "nEpoch=50\n",
    "nIteration=100\n",
    "\n",
    "print(\"Alpha:\", alpha, \"\\n\")\n",
    "betaTT, cpuTT = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaTT  = [item for sublist in betaTT for item in sublist]\n",
    "betaTT = pd.DataFrame(betaTT)[:21]\n",
    "\n",
    "\n",
    "alpha = 0.001\n",
    "print(\"\\nAlpha:\", alpha, \"\\n\")\n",
    "betaT, cpuT = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaT  = [item for sublist in betaT for item in sublist]\n",
    "betaT = pd.DataFrame(betaT)[:21]\n",
    "\n",
    "alpha = 0.05\n",
    "print(\"\\nAlpha:\", alpha, \"\\n\")\n",
    "betaF, cpuF = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaF  = [item for sublist in betaF for item in sublist]\n",
    "betaF = pd.DataFrame(betaF)[:21]\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "print(\"\\nAlpha:\", alpha, \"\\n\")\n",
    "betaH, cpuH = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaH  = [item for sublist in betaH for item in sublist]\n",
    "betaH = pd.DataFrame(betaH)[:21]\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "print(\"\\nAlpha:\", alpha, \"\\n\")\n",
    "betaTen, cpuTen = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaTen  = [item for sublist in betaTen for item in sublist]\n",
    "betaTen = pd.DataFrame(betaTen)[:21]\n",
    "\n",
    "\n",
    "alpha = 1.0\n",
    "print(\"\\nAlpha:\", alpha, \"\\n\")\n",
    "betaOne, cpuOne = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,alpha,nEpoch,nIteration)\n",
    "betaOne  = [item for sublist in betaOne for item in sublist]\n",
    "betaOne = pd.DataFrame(betaOne)[:21]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y predictions for alpha = {0.0001, 0.001, 0.05, 0.01, 0.1, 1.0}\n",
    "\n",
    "y_predTT = linear_regression_gd_stochastic_predict(betaTT,X_test_scaled_std)\n",
    "y_predTT  = [item for sublist in y_predTT for item in sublist]\n",
    "y_predTT = pd.DataFrame(y_predTT )\n",
    "\n",
    "y_predT = linear_regression_gd_stochastic_predict(betaT,X_test_scaled_std)\n",
    "y_predT  = [item for sublist in y_predT for item in sublist]\n",
    "y_predT = pd.DataFrame(y_predT )\n",
    "\n",
    "y_predF = linear_regression_gd_stochastic_predict(betaF,X_test_scaled_std)\n",
    "y_predF  = [item for sublist in y_predF for item in sublist]\n",
    "y_predF = pd.DataFrame(y_predF)\n",
    "\n",
    "y_predH = linear_regression_gd_stochastic_predict(betaH,X_test_scaled_std)\n",
    "y_predH  = [item for sublist in y_predH for item in sublist]\n",
    "y_predH = pd.DataFrame(y_predH)\n",
    "\n",
    "y_predTen = linear_regression_gd_stochastic_predict(betaTen,X_test_scaled_std)\n",
    "y_predTen  = [item for sublist in y_predTen for item in sublist]\n",
    "y_predTen = pd.DataFrame(y_predTen)\n",
    "\n",
    "y_predOne = linear_regression_gd_stochastic_predict(betaOne,X_test_scaled_std)\n",
    "y_predOne  = [item for sublist in y_predOne for item in sublist]\n",
    "y_predOne = pd.DataFrame(y_predOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE \n",
    "rmseList = []\n",
    "\n",
    "RMSETT = RMSE(y_test,y_predTT)\n",
    "\n",
    "RMSET = RMSE(y_test,y_predT)\n",
    "\n",
    "RMSEF = RMSE(y_test,y_predF)\n",
    "\n",
    "RMSEH = RMSE(y_test,y_predH)\n",
    "\n",
    "RMSETen = RMSE(y_test,y_predTen)\n",
    "\n",
    "RMSEOne = RMSE(y_test,y_predOne)\n",
    "\n",
    "rmseList.append(RMSETT)\n",
    "rmseList.append(RMSET)\n",
    "rmseList.append(RMSEF)\n",
    "rmseList.append(RMSEH)\n",
    "rmseList.append(RMSETen)\n",
    "rmseList.append(RMSEOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>19.594854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>23.364722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>29.877812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>11.244098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>14.455542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>9.446867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate       RMSE\n",
       "0         0.0001  19.594854\n",
       "1         0.0010  23.364722\n",
       "2         0.0500  29.877812\n",
       "3         0.0100  11.244098\n",
       "4         0.1000  14.455542\n",
       "5         1.0000   9.446867"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, print the learning rate that shows the best test performance, \n",
    "#and also print as a pandas dataframe named summary with 2 columns: {learning_rate, test_RMSE} \n",
    "#containing RMSE's of the 6 linear regression models. Also, print the best performing learning rate.\n",
    "\n",
    "learnRate = pd.DataFrame()\n",
    "learnRate[\"Learning Rate\"] = learningRate\n",
    "learnRate[\"RMSE\"] = rmseList\n",
    "\n",
    "learnRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Learning Rate      RMSE\n",
      "5            1.0  9.446867\n"
     ]
    }
   ],
   "source": [
    "#best learning rate \n",
    "print(learnRate[learnRate.RMSE == learnRate.RMSE.min()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 17:\n",
    "* Utilizing the best trained linear regression model (so far), predict the target for each of the samples in the judge_dataset.\n",
    "    * I believe you will not forget to do the following before call in the prediction algorithm:\n",
    "        - Save the ID values of the judge dataset into ID_judge and drop it from the judge dataframe.\n",
    "        - Perform onehot encoding using the same encoder you used to encode X_test (Task 4). \n",
    "        - keep only the same top 20 variables as you did in Task 7. \n",
    "        - scale the input variables based on the same metrics you used to scale the training dataset (Task 9). \n",
    "    * Now, call the prediction function of that model to obtain y_pred.\n",
    "    * Prepare and print as a pandas dataframe having columns: {ID, BWEIGHT}, where ID will the ID of the judge sample, and BWEIGHT is the corresponding y_pred value from your model prediction.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "judgeX = judge_dataset.iloc[:, judge_dataset.columns != 'BWEIGHT']\n",
    "\n",
    "judgeY = judge_dataset.iloc[:, judge_dataset.columns == 'BWEIGHT']\n",
    "\n",
    "judgeX_train, judgeX_test, judgeY_train, judgeY_test = train_test_split(judgeX, judgeY, test_size=0.25,  random_state=45931)\n",
    "\n",
    "#saving ID columns\n",
    "judgeX_ID_train = judgeX_train[\"ID\"]\n",
    "judgeX_ID_test = judgeX_test[\"ID\"] \n",
    "\n",
    "\n",
    "#removing ID columns\n",
    "judgeX_train =judgeX_train.iloc[:, judgeX_train.columns != 'ID'] \n",
    "judgeX_test = judgeX_test.iloc[:, judgeX_test.columns != 'ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE\n",
    "categorical_feature_mask = judgeX_train.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = judgeX_train.columns[categorical_feature_mask].tolist()\n",
    "cat_columns_idx = [judgeX_train.columns.get_loc(col) \n",
    "                   for col in categorical_cols]\n",
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_cols),\n",
    "    remainder='passthrough')\n",
    "\n",
    "judgeX_train_ohe = pd.DataFrame(column_trans.fit_transform(judgeX_train),columns=column_trans.get_feature_names())\n",
    "\n",
    "judgeX_test_ohe = pd.DataFrame(column_trans.transform(judgeX_test),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missings\n",
    "\n",
    "#train\n",
    "missingTrain = judgeX_train_ohe[judgeX_train_ohe.isnull().any(axis=1)]  \n",
    "judgeX_train_ohe_imputed = judgeX_train_ohe.fillna(judgeX_train_ohe.mean())\n",
    "\n",
    "#test\n",
    "missingTest = judgeX_test_ohe[judgeX_test_ohe.isnull().any(axis=1)]  \n",
    "judgeX_test_ohe_imputed = judgeX_test_ohe.fillna(judgeX_test_ohe.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make corr scores\n",
    "#JUDGE TRAIN\n",
    "\n",
    "judgeX_train_corr = pd.DataFrame()\n",
    "\n",
    "#pearson method\n",
    "judgeX_train_corr = judgeX_train_ohe_imputed.corrwith(y_train[\"BWEIGHT\"] , axis=0, drop=True, method='pearson')\n",
    "\n",
    "\n",
    "#naming the columns \n",
    "judgeX_train_corr = judgeX_train_corr.rename_axis(\"Variable\").reset_index()\n",
    "judgeX_train_corr.rename(columns={judgeX_train_corr.columns[1]: \"Corr Score\" }, inplace = True)\n",
    "\n",
    "#sorting by the abs of corr score and taking top 20 in two columns \n",
    "Judge_Train_top20 = judgeX_train_corr.sort_values(by = \"Corr Score\", ascending = False, key = abs).iloc[:20]\n",
    "#Judge_Train_top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUDGE TEST\n",
    "\n",
    "judgeX_test_corr = pd.DataFrame()\n",
    "\n",
    "#pearson method\n",
    "judgeX_test_corr = judgeX_test_ohe_imputed.corrwith(y_train[\"BWEIGHT\"] , axis=0, drop=True, method='pearson')\n",
    "\n",
    "\n",
    "#naming the columns \n",
    "judgeX_test_corr = judgeX_test_corr.rename_axis(\"Variable\").reset_index()\n",
    "judgeX_test_corr.rename(columns={judgeX_test_corr.columns[1]: \"Corr Score\" }, inplace = True)\n",
    "\n",
    "#sorting by the abs of corr score and taking top 20 in two columns \n",
    "Judge_Test_top20 = judgeX_test_corr.sort_values(by = \"Corr Score\", ascending = False, key = abs).iloc[:20]\n",
    "#Judge_Test_top20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALED TRAIN\n",
    "jList = [i for i in Judge_Train_top20[\"Variable\"].values]\n",
    "\n",
    "JTRAIN  =  judgeX_train_ohe_imputed.loc[:,jList]\n",
    "\n",
    "JTRAIN_scaled = JTRAIN.copy()\n",
    "\n",
    "\n",
    "JTRAIN_scaled =(JTRAIN_scaled-JTRAIN_scaled.mean())/JTRAIN_scaled.std()\n",
    "#JTRAIN_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled Test\n",
    "jTestList = [i for i in Judge_Test_top20[\"Variable\"].values]\n",
    "\n",
    "JTest  =  judgeX_test_ohe_imputed.loc[:,jTestList ]\n",
    "\n",
    "JTest_scaled = JTest.copy()\n",
    "\n",
    "\n",
    "JTest_scaled =(JTest_scaled-JTest_scaled.mean())/JTest_scaled.std()\n",
    "#JTest_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>onehotencoder__x1_P</th>\n",
       "      <th>...</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      onehotencoder__x0_M  onehotencoder__x0_N  onehotencoder__x0_O  \\\n",
       "0                     0.0                  1.0                  0.0   \n",
       "1                     0.0                  1.0                  0.0   \n",
       "2                     0.0                  0.0                  0.0   \n",
       "3                     0.0                  1.0                  0.0   \n",
       "4                     0.0                  1.0                  0.0   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                  0.0                  1.0                  0.0   \n",
       "1996                  0.0                  1.0                  0.0   \n",
       "1997                  0.0                  1.0                  0.0   \n",
       "1998                  0.0                  1.0                  0.0   \n",
       "1999                  0.0                  1.0                  0.0   \n",
       "\n",
       "      onehotencoder__x0_P  onehotencoder__x0_S  onehotencoder__x1_C  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "1                     0.0                  0.0                  0.0   \n",
       "2                     0.0                  1.0                  0.0   \n",
       "3                     0.0                  0.0                  0.0   \n",
       "4                     0.0                  0.0                  0.0   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                  0.0                  0.0                  0.0   \n",
       "1996                  0.0                  0.0                  0.0   \n",
       "1997                  0.0                  0.0                  0.0   \n",
       "1998                  0.0                  0.0                  0.0   \n",
       "1999                  0.0                  0.0                  0.0   \n",
       "\n",
       "      onehotencoder__x1_M  onehotencoder__x1_N  onehotencoder__x1_O  \\\n",
       "0                     0.0                  1.0                  0.0   \n",
       "1                     0.0                  1.0                  0.0   \n",
       "2                     0.0                  1.0                  0.0   \n",
       "3                     0.0                  1.0                  0.0   \n",
       "4                     0.0                  1.0                  0.0   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                  0.0                  1.0                  0.0   \n",
       "1996                  0.0                  1.0                  0.0   \n",
       "1997                  0.0                  1.0                  0.0   \n",
       "1998                  0.0                  1.0                  0.0   \n",
       "1999                  0.0                  1.0                  0.0   \n",
       "\n",
       "      onehotencoder__x1_P  ...  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  \\\n",
       "0                     0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1                     0.0  ...       1.0      0.0      0.0     0.0     0.0   \n",
       "2                     0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "3                     0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "4                     0.0  ...       0.0      0.0      1.0     0.0     0.0   \n",
       "...                   ...  ...       ...      ...      ...     ...     ...   \n",
       "1995                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1996                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1997                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1998                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "1999                  0.0  ...       0.0      0.0      0.0     0.0     0.0   \n",
       "\n",
       "      PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0         0.0      0.0    0.0    0.0      0.0  \n",
       "1         0.0      0.0    0.0    0.0      0.0  \n",
       "2         0.0      0.0    0.0    0.0      0.0  \n",
       "3         0.0      0.0    0.0    0.0      0.0  \n",
       "4         0.0      0.0    0.0    0.0      0.0  \n",
       "...       ...      ...    ...    ...      ...  \n",
       "1995      0.0      0.0    0.0    0.0      0.0  \n",
       "1996      0.0      0.0    1.0    0.0      0.0  \n",
       "1997      0.0      0.0    0.0    0.0      0.0  \n",
       "1998      0.0      0.0    0.0    0.0      0.0  \n",
       "1999      0.0      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[2000 rows x 45 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SCALING THE ENTIRE JUDGE DATASET WITHOUT ID\n",
    "judge = judge_dataset.iloc[:, judge_dataset.columns != 'ID']\n",
    "\n",
    "judgeID = judge_dataset.iloc[:, judge_dataset.columns == 'ID']\n",
    "\n",
    "#OHE\n",
    "judge_ohe = pd.DataFrame(column_trans.fit_transform(judge),columns=column_trans.get_feature_names())\n",
    "\n",
    "#Fill in missing\n",
    "missingjudge = judge_ohe[judge_ohe.isnull().any(axis=1)]  \n",
    "judgeImputed = judge_ohe.fillna(judge_ohe.mean())\n",
    "judgeImputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKE TOP 20\n",
    "#JUDGE ALL \n",
    "\n",
    "judge20 =  judgeImputed.loc[:,tList]\n",
    "\n",
    "judgeDF = judge20.copy()\n",
    "\n",
    "#SCALE ALL\n",
    "J_scale =(judgeDF-judgeDF.mean())/judgeDF.std()\n",
    "\n",
    "#add bias\n",
    "J_scale.insert(loc = 0, column =\"Bias\", value = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID   BWEIGHT\n",
      "0        1  7.660475\n",
      "1        2  7.116063\n",
      "2        3  6.752058\n",
      "3        4  7.157585\n",
      "4        5  7.446532\n",
      "...    ...       ...\n",
      "1995  1996  6.811984\n",
      "1996  1997  7.065062\n",
      "1997  1998  7.380750\n",
      "1998  1999  7.273306\n",
      "1999  2000  7.132013\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "JY_pred = linear_regression_closed_form_predict(betas_closed_form, J_scale)\n",
    "\n",
    "JY_pred = [item for sublist in JY_pred for item in sublist]\n",
    "\n",
    "jSample = pd.DataFrame()\n",
    "jSample[\"BWEIGHT\"] = JY_pred[:2000]\n",
    "\n",
    "\n",
    "jSample.insert(0, 'ID', range(1, 2001))\n",
    "print(jSample)\n",
    "\n",
    "jSample.to_csv('Assignment2Done.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Students only\n",
    "## Task 18:\n",
    "Bring your best model and submit your solution at https://www.kaggle.com/c/birth-weight-prediction Submit multiple entries. Demonstrate your effort by pushing yourself to improve your own score or beat other submissions (if any available) until the deadline and document your scores and list what changes you made in your submitted solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "# APPARENTLY - the count for the submission must start at index 1, so i removed my beta 0 argument\n",
    "#\n",
    "# Evaluation Exception: Submission must have 2000 rows\n",
    "#1 and 2 I submitted using closed form - score is 10.29449\n",
    "\n",
    "#3 looked into seeing why I was getting different values than everyone else so I got mad and kept on trying different ways\n",
    "#like taking the absolute value at the end. That lowered me to 9.58546\n",
    "\n",
    "#4 Took the absolute values at the corr scores before- but should not have mattered \n",
    "\n",
    "#5 REALIZED THAT I WAS MULTIPLYING BY THE ONES BIAS COLUMN AND NOT ACTUAL X TRANSPOSE\n",
    "#omg lol \n",
    "#fixed entire thing, 9.58546\n",
    "\n",
    "#6 unabsolute valued it 7.29037\n",
    "\n",
    "#7. I REALIZED I WAS DOING THE WHOLE THING WRONG\n",
    "#I WAS SPLITTING THE ENTIRE DATASET AND TRAINING THEM\n",
    "# JUST DO THE WHOLE ASS JUDGE SET AND PASS IN BETAS FROM CLOSED FORM \n",
    "#ADFADFASDF OMFG 1.45061\n",
    "# I CAN'T\n",
    "#sorry so dumb\n",
    "#RIP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
